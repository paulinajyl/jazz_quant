{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b15e692",
   "metadata": {},
   "source": [
    "# setup\n",
    "libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccbaa4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install community -q\n",
    "!pip install pretty_midi pydub PyWavelets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e11835",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "######### necessary libraries #########\n",
    "import pretty_midi\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "import pywt\n",
    "import scipy.signal\n",
    "from scipy.signal import correlate\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy.interpolate import interp1d\n",
    "from matplotlib.patches import Patch\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b7b0a",
   "metadata": {},
   "source": [
    "## data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd25fff",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "######### data cleaning/preprocessing functions #########\n",
    "def combine_mp3(path, common_file_name, num_files):\n",
    "    '''\n",
    "    Combine multiple MP3 files into a single MP3 file.\n",
    "    \n",
    "    Parameters:\n",
    "        path (str): Path to the directory containing the MP3 files\n",
    "        common_file_name (str): Prefix of the MP3 files (e.g., \"song\" for \"song1.mp3\", \"song2.mp3\", etc.)\n",
    "        num_files (int): Number of files to combine\n",
    "    \n",
    "    Returns:\n",
    "        None: The function saves the combined file to disk as \"combined_{common_file_name}.mp3\"\n",
    "    '''\n",
    "    # Initialize an empty list to store the file paths\n",
    "    mp3_files = []\n",
    "\n",
    "    for i in range(1, num_files+1):\n",
    "        mp3_file = f\"{path}/{common_file_name}{i}.mp3\"\n",
    "        print(f\"--------Appending {common_file_name}{i} to list of mp3 files--------\")\n",
    "        mp3_files.append(mp3_file)\n",
    "    print(\"--------File appending complete--------\")\n",
    "\n",
    "    print(\"--------Loading first file--------\")\n",
    "    combined_audio = AudioSegment.from_mp3(mp3_files[0])\n",
    "\n",
    "    print(\".\\n.\\n.\\n\")\n",
    "    # Append each additional file\n",
    "    for mp3_file in mp3_files[1:]:\n",
    "        print(f\"--------Adding {mp3_file} to the combined audio segment--------\")\n",
    "        audio_segment = AudioSegment.from_mp3(mp3_file)\n",
    "        combined_audio += audio_segment  \n",
    "\n",
    "    # Export the concatenated audio to a new file\n",
    "    combined_audio.export(f\"{path}/combined_{common_file_name}.mp3\", format=\"mp3\")\n",
    "\n",
    "    print(f\"Files concatenated successfully into combined_{common_file_name}.mp3\")\n",
    "\n",
    "def mp3_to_wav(mp3_filename, wav_filename):\n",
    "    '''\n",
    "    Convert an MP3 file to WAV format.\n",
    "    \n",
    "    Parameters:\n",
    "        mp3_filename (str): Path to the input MP3 file\n",
    "        wav_filename (str): Path for the output WAV file\n",
    "    \n",
    "    Returns:\n",
    "        None: The function saves the WAV file to disk\n",
    "    '''\n",
    "    # Load MP3 file using pydub\n",
    "    audio = AudioSegment.from_mp3(mp3_filename)\n",
    "    \n",
    "    # Export audio as WAV\n",
    "    audio.export(wav_filename, format=\"wav\")\n",
    "    print(f\"WAV file saved as {wav_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aee1c8",
   "metadata": {},
   "source": [
    "## data analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95525c15",
   "metadata": {},
   "source": [
    "### midi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abac26",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "######### all functions for midi note number analysis #########\n",
    "def get_midi_notes_over_time(midi_data):\n",
    "    '''\n",
    "    Get MIDI notes (pitch) over time.\n",
    "    \n",
    "    Parameters:\n",
    "        midi_data (PrettyMIDI): PrettyMIDI object containing the MIDI data\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - start_times (list): List of note start times\n",
    "            - note_numbers (list): List of MIDI note numbers\n",
    "    '''\n",
    "    # Lists to hold start times and MIDI note numbers\n",
    "    start_times = []\n",
    "    note_numbers = []\n",
    "\n",
    "    # Extract the notes and their start times\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            start_times.append(note.start)\n",
    "            note_numbers.append(note.pitch)\n",
    "\n",
    "    return start_times, note_numbers\n",
    "\n",
    "def get_onset_times(midi_data):\n",
    "    '''\n",
    "    Extract onset times from a MIDI file.\n",
    "    \n",
    "    Parameters:\n",
    "        midi_data (PrettyMIDI): PrettyMIDI object containing the MIDI data\n",
    "    \n",
    "    Returns:\n",
    "        onset_times (list): List of onset times (in seconds)\n",
    "    '''\n",
    "    # Collect all onset times\n",
    "    onset_times = []\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            onset_times.append(note.start)\n",
    "\n",
    "    # Sort onset times\n",
    "    onset_times.sort()\n",
    "    \n",
    "    return onset_times\n",
    "\n",
    "def calculate_iois(midi_data):\n",
    "    '''\n",
    "    Calculate inter-onset intervals (IOIs) from onset times.\n",
    "    \n",
    "    Parameters:\n",
    "        midi_data (PrettyMIDI): PrettyMIDI object containing the MIDI data\n",
    "    \n",
    "    Returns:\n",
    "        iois (np array): Array of inter-onset intervals\n",
    "    '''\n",
    "    onset_times = get_onset_times(midi_data)\n",
    "    iois = np.diff(onset_times)  # Calculate differences between successive onset times\n",
    "    return iois\n",
    "\n",
    "def analyze_midi_distributions(midi_files, labels=None, mode='overlay'):\n",
    "    '''\n",
    "    Analyzes and visualizes MIDI note distributions for multiple MIDI files.\n",
    "    \n",
    "    Parameters:\n",
    "        midi_files (list): List of PrettyMIDI objects already loaded\n",
    "        labels (list, optional): List of labels for each file (defaults to indices if None)\n",
    "        mode (str): Visualization mode - 'individual' for separate plots, 'overlay' for a combined plot\n",
    "    \n",
    "    Returns:\n",
    "        results (dict): Dictionary with indices as keys and (note_counts, stats) as values\n",
    "              where stats is a dictionary containing mean, min, max, variance, and std\n",
    "    '''\n",
    "    from collections import Counter\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set default labels if not provided\n",
    "    if labels is None:\n",
    "        labels = [f\"MIDI {i+1}\" for i in range(len(midi_files))]\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # If overlay mode, prepare a single figure\n",
    "    if mode == 'overlay':\n",
    "        plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Process each file\n",
    "    for i, (midi_file, label) in enumerate(zip(midi_files, labels)):\n",
    "        try:\n",
    "            # Get all notes from all instruments in the MIDI file\n",
    "            notes = [note.pitch for instrument in midi_file.instruments for note in instrument.notes]\n",
    "            \n",
    "            # Count note occurrences\n",
    "            note_counts = Counter(notes)\n",
    "            \n",
    "            # Sort the notes for consistent plotting\n",
    "            sorted_notes = sorted(note_counts.items())\n",
    "            keys, values = zip(*sorted_notes) if sorted_notes else ([], [])\n",
    "            \n",
    "            # Compute descriptive statistics\n",
    "            if notes:\n",
    "                stats = {\n",
    "                    'mean': np.mean(notes),\n",
    "                    'min': np.min(notes),\n",
    "                    'max': np.max(notes),\n",
    "                    'variance': np.var(notes),\n",
    "                    'std': np.std(notes)\n",
    "                }\n",
    "            else:\n",
    "                stats = {\n",
    "                    'mean': 0,\n",
    "                    'min': 0,\n",
    "                    'max': 0,\n",
    "                    'variance': 0,\n",
    "                    'std': 0\n",
    "                }\n",
    "            \n",
    "            # Store results\n",
    "            results[i] = (note_counts, stats)\n",
    "            \n",
    "            # Print descriptive statistics\n",
    "            print(f\"\\nDescriptive Statistics for {label}:\")\n",
    "            print(f\"Mean Note: {stats['mean']:.2f}\")\n",
    "            print(f\"Min Note: {stats['min']}\")\n",
    "            print(f\"Max Note: {stats['max']}\")\n",
    "            print(f\"Variance: {stats['variance']:.2f}\")\n",
    "            print(f\"Standard Deviation: {stats['std']:.2f}\")\n",
    "            \n",
    "            # Visualization\n",
    "            if mode == 'individual':\n",
    "                # Create a separate plot for each file\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.bar(keys, values, color='blue', alpha=0.7)\n",
    "                plt.axvline(stats['mean'], color='red', linestyle='dotted', linewidth=2, \n",
    "                           label=f'Mean={stats[\"mean\"]:.2f}')\n",
    "                plt.xlabel('MIDI Note Number')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.title(f\"Histogram of {label} MIDI Note Frequencies\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            elif mode == 'overlay':\n",
    "                # Add to the overlay plot\n",
    "                plt.bar(keys, values, alpha=0.5, label=f\"{label} (Mean: {stats['mean']:.2f})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing MIDI {i+1}: {e}\")\n",
    "    \n",
    "    # Show the overlay plot if needed\n",
    "    if mode == 'overlay' and results:\n",
    "        plt.xlabel('MIDI Note Number')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(\"Distribution of MIDI Notes\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "#### f-test ####\n",
    "def perform_f_test(var1, var2, n1, n2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs an F-test to determine if two variances are significantly different.\n",
    "    \n",
    "    Parameters:\n",
    "        var1 (float): Variance of the first sample\n",
    "        var2 (float): Variance of the second sample\n",
    "        n1 (int): Size of the first sample\n",
    "        n2 (int): Size of the second sample\n",
    "        alpha (float, optional): Significance level, default is 0.05\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing F-statistic, p-value, and test conclusion\n",
    "    \"\"\"\n",
    "    # Calculate F statistic (ratio of variances)\n",
    "    # Convention is to have the larger variance in the numerator\n",
    "    if var1 > var2:\n",
    "        f_statistic = var1 / var2\n",
    "        df1, df2 = n1 - 1, n2 - 1\n",
    "    else:\n",
    "        f_statistic = var2 / var1\n",
    "        df1, df2 = n2 - 1, n1 - 1\n",
    "    \n",
    "    # Calculate p-value (one-tailed)\n",
    "    p_value = 1 - stats.f.cdf(f_statistic, df1, df2)\n",
    "    \n",
    "    # Two-tailed test (multiply by 2)\n",
    "    p_value_two_tailed = 2 * p_value\n",
    "    \n",
    "    # Test conclusion\n",
    "    conclusion = \"Reject null hypothesis: variances are significantly different\" if p_value_two_tailed < alpha else \"Fail to reject null hypothesis: variances are not significantly different\"\n",
    "    \n",
    "    return {\n",
    "        \"F_statistic\": f_statistic,\n",
    "        \"p_value\": p_value_two_tailed,\n",
    "        \"df1\": df1,\n",
    "        \"df2\": df2,\n",
    "        \"conclusion\": conclusion\n",
    "    }\n",
    "\n",
    "def compare_variances_to_head(moaning_distributions_artists):\n",
    "    \"\"\"\n",
    "    Compares variances of artist distributions to the head distribution using F-tests.\n",
    "    \n",
    "    Parameters:\n",
    "        moaning_distributions_artists (list): List of distribution data for each artist\n",
    "    \n",
    "    Returns:\n",
    "        None: Results are printed to standard output\n",
    "    \"\"\"\n",
    "    # Extract the head distribution from any artist (same for all)\n",
    "    head_distribution = moaning_distributions_artists[0][1][0]  # Using Lee's head as reference\n",
    "    n_head = sum(head_distribution.values())\n",
    "    head_variance = moaning_distributions_artists[0][1][1]['variance']  # Variance of head\n",
    "\n",
    "    # Loop through all artist distributions\n",
    "    artist_names = ['lee', 'fred', 'art', 'roy', 'ter']\n",
    "    for i, distributions in enumerate(moaning_distributions_artists):\n",
    "        # Extract the artist's first distribution (channel 0)\n",
    "        artist_distribution = distributions[0][0]  # Channel 0\n",
    "        n_artist = sum(artist_distribution.values())\n",
    "        artist_variance = distributions[0][1]['variance']\n",
    "\n",
    "        # Perform F-test\n",
    "        result = perform_f_test(artist_variance, head_variance, n_artist, n_head)\n",
    "\n",
    "        # Print results\n",
    "        artist_name = artist_names[i]\n",
    "        print(f\"F-test for equality of variances between {artist_name.capitalize()} and Head\")\n",
    "        print(f\"F-statistic: {result['F_statistic']:.4f}\")\n",
    "        print(f\"p-value: {result['p_value']:.20f}\")\n",
    "        print(f\"Conclusion: {result['conclusion']}\")\n",
    "        print('-' * 50)\n",
    "\n",
    "#### kullback–Llibler divergence ####\n",
    "def calculate_kl_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the Kullback-Leibler divergence between two distributions.\n",
    "\n",
    "    Parameters:\n",
    "        p (Counter or dict): The first distribution (reference).\n",
    "        q (Counter or dict): The second distribution.\n",
    "\n",
    "    Returns:\n",
    "        kl_div (float): KL divergence value.\n",
    "    \"\"\"\n",
    "    # Get all unique notes from both distributions\n",
    "    all_notes = sorted(set(list(p.keys()) + list(q.keys())))\n",
    "    \n",
    "    # Create normalized probability distributions\n",
    "    p_sum = sum(p.values())\n",
    "    q_sum = sum(q.values())\n",
    "    \n",
    "    # Add a small epsilon to avoid division by zero or log(0)\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    p_dist = np.array([p.get(note, 0) / p_sum for note in all_notes])\n",
    "    q_dist = np.array([q.get(note, 0) / q_sum for note in all_notes])\n",
    "    \n",
    "    # Add epsilon to avoid zeros\n",
    "    p_dist = p_dist + epsilon\n",
    "    q_dist = q_dist + epsilon\n",
    "    \n",
    "    # Renormalize\n",
    "    p_dist = p_dist / np.sum(p_dist)\n",
    "    q_dist = q_dist / np.sum(q_dist)\n",
    "    \n",
    "    # Calculate KL divergence\n",
    "    kl_div = np.sum(p_dist * np.log(p_dist / q_dist))\n",
    "    \n",
    "    return kl_div\n",
    "\n",
    "def analyze_and_visualize_divergence(distributions_data, artist_names, title=None):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the KL divergence between artist solos and a head melody.\n",
    "\n",
    "    Parameters:\n",
    "        distributions_data (dict): Dictionary with artist indices as keys and (Counter, ...) tuples as values.\n",
    "        artist_names (list): List of artist names corresponding to indices in distributions_data.\n",
    "        title (str): Optional title for the visualization (default: None).\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a bar chart of KL divergence values.\n",
    "    \"\"\"\n",
    "    # Artist names (maps to keys in the distributions_data)\n",
    "    num_artists = len(artist_names)\n",
    "    artist_indices = list(range(num_artists))\n",
    "    head_index = num_artists  # The head melody\n",
    "    \n",
    "    # Extract distributions\n",
    "    head_distribution = distributions_data[head_index][0]  # First element is the Counter\n",
    "    artist_distributions = [distributions_data[i][0] for i in artist_indices]\n",
    "    \n",
    "    # Calculate head divergence\n",
    "    n_artists = len(artist_names)\n",
    "    head_divergence = np.zeros(n_artists)\n",
    "    \n",
    "    # Calculate artist-to-head divergence\n",
    "    for i, artist_idx in enumerate(artist_indices):\n",
    "        head_divergence[i] = calculate_kl_divergence(artist_distributions[i], head_distribution)\n",
    "    \n",
    "    # Set larger font sizes\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 14,\n",
    "        'axes.titlesize': 18,\n",
    "        'axes.labelsize': 16,\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14\n",
    "    })\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))  # Slightly taller figure to accommodate larger fonts\n",
    "\n",
    "    # 1. Bar chart of divergence from head\n",
    "    metric_name = \"KL Divergence\"\n",
    "    bar_colors = plt.cm.viridis(np.linspace(0, 0.8, n_artists))\n",
    "    ax1.bar(artist_names, head_divergence, color=bar_colors)\n",
    "    \n",
    "    # Set title with optional piece name\n",
    "    if title:\n",
    "        ax1.set_title(f'{metric_name} — {title}', pad=15)\n",
    "    else:\n",
    "        ax1.set_title(f'{metric_name} Between Artists and Head Melody', pad=15)\n",
    "        \n",
    "    ax1.set_ylabel(metric_name)\n",
    "    ax1.set_xlabel('Artists')\n",
    "    \n",
    "    # Need to call this after creating the bars but before rotation\n",
    "    ax1.set_xticks(range(len(artist_names)))\n",
    "    ax1.set_xticklabels(artist_names, rotation=45, ha='right')\n",
    "    \n",
    "    # Add values on top of bars with larger font\n",
    "    for i, v in enumerate(head_divergence):\n",
    "        ax1.text(i, v + max(head_divergence)*0.05, f'{v:.3f}', ha='center', fontsize=14)\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66dcde",
   "metadata": {},
   "source": [
    "### network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486f1b5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "######### all functions for network analysis #########\n",
    "def midi_to_pitch_class(midi_number):\n",
    "    \"\"\"\n",
    "    Convert MIDI note number to pitch class name (ignoring octave).\n",
    "    \n",
    "    Parameters:\n",
    "        midi_number (int): MIDI note number (0-127)\n",
    "        \n",
    "    Returns:\n",
    "        pitch_class (str): Pitch class name (C, C#, D, etc.)\n",
    "    \"\"\"\n",
    "    pitch_classes = ['C', 'Db', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']\n",
    "    return pitch_classes[midi_number % 12]\n",
    "\n",
    "#### just all pitches ####\n",
    "def get_prob_transitions(midi_data):\n",
    "    \"\"\"\n",
    "    Calculate transition probabilities for pitches and inter-onset intervals from a MIDI file.\n",
    "    \n",
    "    Parameters:\n",
    "        midi_data (PrettyMIDI): PrettyMIDI object containing the MIDI data\n",
    "    \n",
    "    Returns:\n",
    "        transition_probs (dict): Dictionary with pitch transition probabilities\n",
    "        iois_probs (dict): Dictionary with IOI probabilities\n",
    "        iois (list): List of inter-onset intervals\n",
    "    \"\"\"\n",
    "    note_times, pitches = get_midi_notes_over_time(midi_data)\n",
    "\n",
    "    # Pitch\n",
    "    # P(A → B) = (Number of times B follows A) / (Total number of transitions in the piece)\n",
    "    transitions = [(pitches[i], pitches[i + 1]) for i in range(len(pitches) - 1)]\n",
    "    transition_counts = Counter(transitions)\n",
    "    total_transitions = sum(transition_counts.values())\n",
    "    transition_probs = {k: v / total_transitions for k, v in transition_counts.items()} if total_transitions > 0 else {}\n",
    "\n",
    "    # Rhythm\n",
    "    # P(IOI = t) = (Number of times IOI value t occurs) / (Total number of IOIs in the piece)\n",
    "    iois = np.diff(sorted(note_times))\n",
    "    iois_counts = Counter(iois)\n",
    "    total_iois = sum(iois_counts.values())\n",
    "    iois_probs = {k: v / total_iois for k, v in iois_counts.items()} if total_iois > 0 else {}\n",
    "\n",
    "    return transition_probs, iois_probs, iois\n",
    "\n",
    "def visualize_strongest_trans(transitions, \n",
    "                               plot_type='overlay',\n",
    "                               top_n=5,\n",
    "                               title=\"Strongest Pitch Transition Network\",\n",
    "                               labels=None,\n",
    "                               edge_colors=None,\n",
    "                               edge_thickness=30,\n",
    "                               prob_threshold=0.01,\n",
    "                               fixed_positions=None):\n",
    "    \"\"\"\n",
    "    Filters and visualizes only the strongest connections by selecting the most active nodes.\n",
    "    \n",
    "    Parameters:\n",
    "        transitions (list): List of transition dictionaries where each dict maps (from_pitch, to_pitch) -> probability\n",
    "        plot_type (str): 'overlay' for single plot with all transitions, 'individual' for separate plots\n",
    "        top_n (int): Number of highest-activity nodes to retain in the network\n",
    "        title (str or list): Graph title(s). If list, must match length of transitions for 'individual' mode\n",
    "        labels (list): Labels for each transition dictionary. Must match length of transitions\n",
    "        edge_colors (list): Colors for edges. Must match length of transitions\n",
    "        edge_thickness (int): Base multiplier for edge thickness\n",
    "        prob_threshold (float): Minimum probability to display edge labels\n",
    "        fixed_positions (dict): Dictionary mapping node IDs to (x,y) coordinates. If None, positions are calculated once and reused\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (Graph object(s), node positions dictionary)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Validate and prepare inputs\n",
    "    n_networks = len(transitions)\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = [f\"Network {i+1}\" for i in range(n_networks)]\n",
    "    \n",
    "    # Compute node activity from all transitions combined\n",
    "    node_activity = {}\n",
    "    for transition_dict in transitions:\n",
    "        for (from_pitch, to_pitch), probability in transition_dict.items():\n",
    "            node_activity[from_pitch] = node_activity.get(from_pitch, 0) + probability\n",
    "            node_activity[to_pitch] = node_activity.get(to_pitch, 0) + probability\n",
    "\n",
    "    # Select the top N most active nodes\n",
    "    top_nodes = set(sorted(node_activity, key=node_activity.get, reverse=True)[:top_n])\n",
    "    \n",
    "    # Create new filtered transition dictionaries\n",
    "    filtered_transitions = []\n",
    "    for transition_dict in transitions:\n",
    "        filtered_dict = {k: v for k, v in transition_dict.items() if k[0] in top_nodes and k[1] in top_nodes}\n",
    "        filtered_transitions.append(filtered_dict)\n",
    "\n",
    "    # Call the modified visualization function with the filtered data\n",
    "    return visualize_all_pitch_trans(filtered_transitions, \n",
    "                                      plot_type=plot_type,\n",
    "                                      title=title,\n",
    "                                      labels=labels, \n",
    "                                      edge_colors=edge_colors,\n",
    "                                      edge_thickness=edge_thickness,\n",
    "                                      prob_threshold=prob_threshold,\n",
    "                                      fixed_positions=fixed_positions)\n",
    "\n",
    "def visualize_all_pitch_trans(transitions, \n",
    "                             plot_type='overlay',\n",
    "                             title=\"Directed Weighted Pitch Transition Network\",\n",
    "                             labels=None,\n",
    "                             edge_colors=None,\n",
    "                             edge_thickness=30,\n",
    "                             prob_threshold=0.01,\n",
    "                             fixed_positions=None):\n",
    "    \"\"\"\n",
    "    Create a network graph visualization with directed, weighted edges, probability labels,\n",
    "    and nodes colored based on activity.\n",
    "    \n",
    "    Parameters:\n",
    "        transitions (list): List of transition dictionaries where each dict maps (from_pitch, to_pitch) -> probability\n",
    "        plot_type (str): 'overlay' for single plot with all transitions, 'individual' for separate plots\n",
    "        title (str or list): Graph title(s). If list, must match length of transitions for 'individual' mode\n",
    "        labels (list): Labels for each transition dictionary. Must match length of transitions\n",
    "        edge_colors (list): Colors for edges. Must match length of transitions\n",
    "        edge_thickness (int): Base multiplier for edge thickness\n",
    "        prob_threshold (float): Minimum probability to display edge labels\n",
    "        fixed_positions (dict): Dictionary mapping node IDs to (x,y) coordinates. If None, positions are calculated once and reused\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (Graph object(s), node positions dictionary)\n",
    "    \"\"\"\n",
    "    # Validate and prepare inputs\n",
    "    n_networks = len(transitions)\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = [f\"Network {i+1}\" for i in range(n_networks)]\n",
    "    elif len(labels) != n_networks:\n",
    "        raise ValueError(f\"Number of labels ({len(labels)}) must match number of transition sets ({n_networks})\")\n",
    "    \n",
    "    if edge_colors is None:\n",
    "        # Use a colormap to automatically generate colors\n",
    "        cmap = plt.cm.get_cmap('tab10')\n",
    "        edge_colors = [cmap(i % 10) for i in range(n_networks)]\n",
    "    elif len(edge_colors) != n_networks:\n",
    "        raise ValueError(f\"Number of edge colors ({len(edge_colors)}) must match number of transition sets ({n_networks})\")\n",
    "        \n",
    "    if isinstance(title, list) and plot_type == 'individual' and len(title) != n_networks:\n",
    "        raise ValueError(f\"Number of titles ({len(title)}) must match number of transition sets ({n_networks})\")\n",
    "\n",
    "    def midi_to_note_name(midi_num):\n",
    "        notes = ['C', 'Db', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B']\n",
    "        octave = midi_num // 12 - 1\n",
    "        note = notes[midi_num % 12]\n",
    "        return f\"{note}{octave}\"\n",
    "    \n",
    "    # Create a combined graph with all nodes first to establish fixed positions\n",
    "    G_for_positions = nx.DiGraph()\n",
    "    all_nodes = set()\n",
    "    \n",
    "    # Collect all nodes from all transition sets\n",
    "    for trans_dict in transitions:\n",
    "        for from_pitch, to_pitch in trans_dict.keys():\n",
    "            all_nodes.add(from_pitch)\n",
    "            all_nodes.add(to_pitch)\n",
    "    \n",
    "    # Add all nodes to the positioning graph\n",
    "    for node in all_nodes:\n",
    "        G_for_positions.add_node(node)\n",
    "    \n",
    "    # Generate positions only once if not provided\n",
    "    global_positions = fixed_positions\n",
    "    if global_positions is None:\n",
    "        global_positions = nx.spring_layout(G_for_positions, k=0.3, iterations=100, seed=42)\n",
    "    \n",
    "    def create_graph(transition_sets, current_labels, current_colors, current_title):\n",
    "        # Create combined graph with all nodes\n",
    "        G_combined = nx.DiGraph()\n",
    "        \n",
    "        # Add edges and compute node activity\n",
    "        node_activity = {}\n",
    "        all_transitions = {}\n",
    "        \n",
    "        # Combine all transitions for node activity calculation\n",
    "        for trans_dict in transition_sets:\n",
    "            all_transitions.update(trans_dict)\n",
    "            \n",
    "        for (from_pitch, to_pitch), probability in all_transitions.items():\n",
    "            G_combined.add_edge(from_pitch, to_pitch, weight=probability)\n",
    "            node_activity[from_pitch] = node_activity.get(from_pitch, 0) + probability\n",
    "            node_activity[to_pitch] = node_activity.get(to_pitch, 0) + probability\n",
    "        \n",
    "        # Normalize activity levels for colormap scaling\n",
    "        activity_values = np.array(list(node_activity.values()))\n",
    "        norm = mcolors.Normalize(vmin=min(activity_values), vmax=max(activity_values))\n",
    "        cmap = cm.get_cmap('viridis')  # Node color map based on activity\n",
    "        node_colors = {node: cmap(norm(activity)) for node, activity in node_activity.items()}\n",
    "        \n",
    "        plt.figure(figsize=(14, 12))\n",
    "        \n",
    "        # Use the pre-computed fixed positions\n",
    "        pos = global_positions\n",
    "        \n",
    "        # Draw nodes\n",
    "        node_labels = {n: midi_to_note_name(n) for n in G_combined.nodes()}\n",
    "        nx.draw_networkx_nodes(G_combined, pos, \n",
    "                              node_size=700, \n",
    "                              node_color=[node_colors[n] for n in G_combined.nodes()],\n",
    "                              edgecolors='black',\n",
    "                              alpha=0.9)\n",
    "        nx.draw_networkx_labels(G_combined, pos, labels=node_labels, font_size=10, font_weight=\"bold\")\n",
    "        \n",
    "        # Draw edges with different colors\n",
    "        legend_handles = []\n",
    "        \n",
    "        for i, transition_dict in enumerate(transition_sets):\n",
    "            edges = [(u, v, w) for (u, v), w in transition_dict.items()]\n",
    "            if edges:\n",
    "                # Calculate scaled edge widths based on weight\n",
    "                edge_widths = [max(w * edge_thickness, 1) for _, _, w in edges]\n",
    "                \n",
    "                # Draw edges with enhanced arrow style\n",
    "                nx.draw_networkx_edges(G_combined, pos,\n",
    "                                      edgelist=[(u, v) for u, v, _ in edges],\n",
    "                                      width=edge_widths,\n",
    "                                      edge_color=current_colors[i],\n",
    "                                      alpha=0.7,\n",
    "                                      arrows=True, \n",
    "                                      arrowsize=20,\n",
    "                                      arrowstyle='-|>', \n",
    "                                      connectionstyle='arc3,rad=0.1')\n",
    "                \n",
    "                # Add to legend\n",
    "                legend_handles.append(Line2D([0], [0], color=current_colors[i], lw=4, label=current_labels[i]))\n",
    "                \n",
    "        # Annotate edges with probability labels (only for significant transitions)\n",
    "        for (u, v, w) in G_combined.edges(data='weight'):\n",
    "            if w >= prob_threshold:\n",
    "                if u == v:  # Self-loop: position label above node\n",
    "                    # Offset the label position above the node\n",
    "                    xy = (pos[u][0], pos[u][1] + 0.06)  # Adjust the y-coordinate to place the label above\n",
    "                else:\n",
    "                    # Normal edge: position label along the edge\n",
    "                    xy = (pos[u][0] * 0.7 + pos[v][0] * 0.3, pos[u][1] * 0.7 + pos[v][1] * 0.3)\n",
    "        \n",
    "                plt.annotate(f\"{w:.4f}\", \n",
    "                            xy=xy,\n",
    "                            fontsize=9,\n",
    "                            weight='bold',\n",
    "                            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", alpha=0.8))\n",
    "        \n",
    "        # Legend with thicker lines\n",
    "        plt.legend(handles=legend_handles, loc='upper right', fontsize=12)\n",
    "        \n",
    "        # Display node activity using a color bar\n",
    "        sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=plt.gca(), shrink=0.7, aspect=30)\n",
    "        cbar.set_label('Node Activity Level', fontsize=12)\n",
    "        \n",
    "        plt.title(current_title, fontsize=16)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return G_combined\n",
    "    \n",
    "    # Create plots based on plot_type\n",
    "    if plot_type == 'overlay':\n",
    "        # Create a single plot with all transitions\n",
    "        current_title = title if isinstance(title, str) else \"Directed Weighted Pitch Transition Network\"\n",
    "        G = create_graph(transitions, labels, edge_colors, current_title)\n",
    "        plt.show()\n",
    "        return G, global_positions\n",
    "    \n",
    "    elif plot_type == 'individual':\n",
    "        # Create separate plots for each transition set\n",
    "        graphs = []\n",
    "        titles = title if isinstance(title, list) else [f\"{labels[i]} Transitions\" for i in range(n_networks)]\n",
    "        \n",
    "        for i, trans in enumerate(transitions):\n",
    "            current_title = titles[i]\n",
    "            G = create_graph([trans], [labels[i]], [edge_colors[i]], current_title)\n",
    "            graphs.append(G)\n",
    "            plt.show()\n",
    "        \n",
    "        return graphs, global_positions\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"plot_type must be either 'overlay' or 'individual'\")\n",
    "\n",
    "#### only pitches, no octaves ####\n",
    "def extract_transitions_from_midi(midi_file_path):\n",
    "    \"\"\"\n",
    "    Extract chromatic and interval transitions from a MIDI file.\n",
    "    \n",
    "    Parameters:\n",
    "        midi_file_path (str): Path to the MIDI file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Collection of transition dictionaries in the order:\n",
    "               (chromatic_transitions, diatonic_transitions, third_transitions,\n",
    "                fourth_transitions, fifth_transitions, sixth_transitions,\n",
    "                seventh_transitions, octave_transitions)\n",
    "    \"\"\"\n",
    "    import pretty_midi\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # the interval categories\n",
    "    interval_categories = {\n",
    "        'chromatic': (1,),      # Chromatic (1 semitone)\n",
    "        'diatonic': (2,),       # Whole tone/diatonic (2 semitones)\n",
    "        'third': (3, 4),        # Minor third (3 semitones) and major third (4 semitones)\n",
    "        'fourth': (5,),         # Perfect fourth (5 semitones)\n",
    "        'fifth': (7,),          # Perfect fifth (7 semitones)\n",
    "        'sixth': (8, 9),        # Minor sixth (8 semitones) and major sixth (9 semitones)\n",
    "        'seventh': (10, 11),    # Minor seventh (10 semitones) and major seventh (11 semitones)\n",
    "        'octave': (12,)         # Octave (12 semitones)\n",
    "    }\n",
    "    \n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "    \n",
    "    # Get all notes from all instruments\n",
    "    all_notes = []\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            all_notes.append({\n",
    "                'note': note.pitch,\n",
    "                'start_time': note.start,\n",
    "                'end_time': note.end,\n",
    "                'velocity': note.velocity,\n",
    "                'instrument': instrument.program,\n",
    "                'is_drum': instrument.is_drum\n",
    "            })\n",
    "    \n",
    "    # Group notes by instrument (each instrument might represent a different voice)\n",
    "    notes_by_instrument = defaultdict(list)\n",
    "    for note in sorted(all_notes, key=lambda x: x['start_time']):\n",
    "        # Create a unique identifier for each instrument\n",
    "        instrument_id = (note['instrument'], note['is_drum'])\n",
    "        notes_by_instrument[instrument_id].append(note)\n",
    "    \n",
    "    # Initialize transition dictionaries\n",
    "    transitions = {\n",
    "        'chromatic': defaultdict(float),\n",
    "        'diatonic': defaultdict(float),\n",
    "        'third': defaultdict(float),\n",
    "        'fourth': defaultdict(float),\n",
    "        'fifth': defaultdict(float),\n",
    "        'sixth': defaultdict(float),\n",
    "        'seventh': defaultdict(float),\n",
    "        'octave': defaultdict(float)\n",
    "    }\n",
    "    \n",
    "    # Minimum sequence length for detecting patterns\n",
    "    min_seq_length = 3\n",
    "    \n",
    "    # Process each instrument's notes\n",
    "    for instrument_id, instrument_notes in notes_by_instrument.items():\n",
    "        # Skip drum tracks for melodic analysis\n",
    "        if instrument_id[1]:  # is_drum\n",
    "            continue\n",
    "            \n",
    "        # Sort by start time\n",
    "        instrument_notes.sort(key=lambda x: x['start_time'])\n",
    "        \n",
    "        # Analyze transitions\n",
    "        for i in range(len(instrument_notes) - 1):\n",
    "            current_note = instrument_notes[i]['note']\n",
    "            next_note = instrument_notes[i+1]['note']\n",
    "            transition = (current_note, next_note)\n",
    "            \n",
    "            # Calculate pitch difference\n",
    "            pitch_diff = abs(next_note - current_note)\n",
    "            \n",
    "            # Classify the interval\n",
    "            for category, intervals in interval_categories.items():\n",
    "                if pitch_diff in intervals:\n",
    "                    transitions[category][transition] += 1\n",
    "            \n",
    "            # Analyze sequences of similar intervals\n",
    "            direction = 1 if next_note > current_note else -1 if next_note < current_note else 0\n",
    "            \n",
    "            # Check for sequences of similar intervals\n",
    "            for category, intervals in interval_categories.items():\n",
    "                if pitch_diff in intervals:\n",
    "                    # Check for sequence\n",
    "                    seq_length = 2  # Start with current two notes\n",
    "                    for j in range(i+1, len(instrument_notes)-1):\n",
    "                        next_diff = abs(instrument_notes[j+1]['note'] - instrument_notes[j]['note'])\n",
    "                        next_direction = 1 if instrument_notes[j+1]['note'] > instrument_notes[j]['note'] else -1 if instrument_notes[j+1]['note'] < instrument_notes[j]['note'] else 0\n",
    "                        \n",
    "                        # Check if this is the same interval type and direction\n",
    "                        if next_diff in intervals and next_direction == direction:\n",
    "                            seq_length += 1\n",
    "                        else:\n",
    "                            break\n",
    "                    \n",
    "                    # If we found a sequence of at least min_seq_length notes\n",
    "                    if seq_length >= min_seq_length:\n",
    "                        # Add all transitions in this sequence \n",
    "                        for k in range(i, i+seq_length-1):\n",
    "                            trans = (instrument_notes[k]['note'], instrument_notes[k+1]['note'])\n",
    "                            # Add extra weight to transitions that are part of longer sequences\n",
    "                            transitions[category][trans] += 0.5  # Boost the weight\n",
    "    \n",
    "    # Normalize all transition dictionaries\n",
    "    for category, trans_dict in transitions.items():\n",
    "        total = sum(trans_dict.values())\n",
    "        if total > 0:\n",
    "            transitions[category] = {k: v/total for k, v in trans_dict.items()}\n",
    "        else:\n",
    "            transitions[category] = dict()\n",
    "    \n",
    "    # Return the transition dictionaries in the requested order\n",
    "    return (\n",
    "        transitions['chromatic'],\n",
    "        transitions['diatonic'],\n",
    "        transitions['third'],\n",
    "        transitions['fourth'],\n",
    "        transitions['fifth'],\n",
    "        transitions['sixth'],\n",
    "        transitions['seventh'],\n",
    "        transitions['octave']\n",
    "    )\n",
    "\n",
    "def visualize_pitch_trans_mod(transitions, \n",
    "                                   plot_type='overlay',\n",
    "                                   title=\"Pitch Transition Network\",\n",
    "                                   labels=None,\n",
    "                                   edge_colors=None,\n",
    "                                   save_path=None):\n",
    "    \"\"\"\n",
    "    Create a network graph visualization with notes grouped by pitch class (ignoring octave).\n",
    "    \n",
    "    Parameters:\n",
    "        transitions (list): List of transition dictionaries where each dict maps (from_pitch, to_pitch) -> probability\n",
    "        plot_type (str): 'overlay' for single plot with all transitions, 'individual' for separate plots\n",
    "        title (str or list): Title(s) for the graph(s)\n",
    "        labels (list): Labels for each transition dictionary in the legend\n",
    "        edge_colors (list): Colors to use for each transition set\n",
    "        save_path (str or list): Path(s) to save the figure(s). If None, no saving is performed\n",
    "    \n",
    "    Returns:\n",
    "        graph: Graph objects and positional data for the visualization\n",
    "    \"\"\"\n",
    "    import networkx as nx\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Validate inputs\n",
    "    n_networks = len(transitions)\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = [f\"Network {i+1}\" for i in range(n_networks)]\n",
    "    elif len(labels) != n_networks:\n",
    "        raise ValueError(f\"Number of labels ({len(labels)}) must match number of transition sets ({n_networks})\")\n",
    "    \n",
    "    if edge_colors is None:\n",
    "        # Default color palette\n",
    "        cmap = plt.cm.get_cmap('tab10')\n",
    "        edge_colors = [cmap(i % 10) for i in range(n_networks)]\n",
    "    elif len(edge_colors) != n_networks:\n",
    "        raise ValueError(f\"Number of edge colors ({len(edge_colors)}) must match number of transition sets ({n_networks})\")\n",
    "    \n",
    "    if isinstance(title, list) and plot_type == 'individual' and len(title) != n_networks:\n",
    "        raise ValueError(f\"Number of titles ({len(title)}) must match number of transition sets ({n_networks})\")\n",
    "    \n",
    "    if save_path is not None and isinstance(save_path, list) and plot_type == 'individual' and len(save_path) != n_networks:\n",
    "        raise ValueError(f\"Number of save paths ({len(save_path)}) must match number of transition sets ({n_networks})\")\n",
    "    \n",
    "    def normalize_transitions(transitions):\n",
    "        \"\"\"Normalize transition probabilities for each source pitch class\"\"\"\n",
    "        # Group transitions by source pitch class\n",
    "        source_groups = {}\n",
    "        for (src, dst), prob in transitions.items():\n",
    "            if src not in source_groups:\n",
    "                source_groups[src] = 0\n",
    "            source_groups[src] += prob\n",
    "            \n",
    "        # Normalize by dividing each transition by the total for its source\n",
    "        normalized = {}\n",
    "        for (src, dst), prob in transitions.items():\n",
    "            if source_groups[src] > 0:  # Avoid division by zero\n",
    "                normalized[(src, dst)] = prob / source_groups[src]\n",
    "            else:\n",
    "                normalized[(src, dst)] = 0\n",
    "        return normalized\n",
    "    \n",
    "    def process_transitions(transition_dict):\n",
    "        \"\"\"Convert MIDI note transitions to pitch class transitions and normalize\"\"\"\n",
    "        pc_transitions = {}\n",
    "        \n",
    "        for (from_pitch, to_pitch), probability in transition_dict.items():\n",
    "            from_pc = midi_to_pitch_class(from_pitch)\n",
    "            to_pc = midi_to_pitch_class(to_pitch)\n",
    "            \n",
    "            # Add or update the pitch class transition probability\n",
    "            pc_key = (from_pc, to_pc)\n",
    "            if pc_key in pc_transitions:\n",
    "                pc_transitions[pc_key] += probability\n",
    "            else:\n",
    "                pc_transitions[pc_key] = probability\n",
    "        \n",
    "        # Normalize to make them probabilities again\n",
    "        return normalize_transitions(pc_transitions)\n",
    "    \n",
    "    # Process all transition dictionaries\n",
    "    all_pc_transitions = [process_transitions(trans) for trans in transitions]\n",
    "    \n",
    "    # Create layout - arrange pitch classes in a circle of fifths\n",
    "    circle_of_fifths = ['C', 'G', 'D', 'A', 'E', 'B', 'F#', 'Db', 'Ab', 'Eb', 'Bb', 'F']\n",
    "    pos = {}\n",
    "    n_nodes = len(circle_of_fifths)\n",
    "    for i, pc in enumerate(circle_of_fifths):\n",
    "        angle = 2 * np.pi * i / n_nodes\n",
    "        pos[pc] = (np.cos(angle), np.sin(angle))\n",
    "    \n",
    "    # Define note colors for consistent appearance\n",
    "    note_colors = {\n",
    "        'C': '#FF0000',   # Red\n",
    "        'Db': '#FF7F00',  # Orange\n",
    "        'D': '#FFFF00',   # Yellow\n",
    "        'Eb': '#7FFF00',  # Chartreuse\n",
    "        'E': '#00FF00',   # Green\n",
    "        'F': '#00FF7F',   # Spring Green\n",
    "        'F#': '#00FFFF',  # Cyan\n",
    "        'G': '#007FFF',   # Azure\n",
    "        'Ab': '#0000FF',  # Blue\n",
    "        'A': '#7F00FF',   # Violet\n",
    "        'Bb': '#FF00FF',  # Magenta\n",
    "        'B': '#FF007F',   # Rose\n",
    "    }\n",
    "    \n",
    "    def create_plot(pc_transitions_list, current_labels, current_colors, current_title, current_save_path=None):\n",
    "        \"\"\"Create a plot for the given transitions\"\"\"\n",
    "        # Extract all unique pitch classes\n",
    "        pitch_classes = set()\n",
    "        for pc_trans in pc_transitions_list:\n",
    "            for from_pc, to_pc in pc_trans.keys():\n",
    "                pitch_classes.add(from_pc)\n",
    "                pitch_classes.add(to_pc)\n",
    "        \n",
    "        # Create graphs\n",
    "        graphs = []\n",
    "        for pc_trans in pc_transitions_list:\n",
    "            G = nx.DiGraph()\n",
    "            \n",
    "            # Add nodes\n",
    "            for pc in pitch_classes:\n",
    "                G.add_node(pc)\n",
    "            \n",
    "            # Add edges\n",
    "            for (from_pc, to_pc), probability in pc_trans.items():\n",
    "                if probability > 0:\n",
    "                    G.add_edge(from_pc, to_pc, weight=probability)\n",
    "            \n",
    "            graphs.append(G)\n",
    "        \n",
    "        plt.figure(figsize=(14, 14))\n",
    "        \n",
    "        # Draw nodes only once\n",
    "        node_color_list = [note_colors.get(node, '#AAAAAA') for node in pitch_classes]\n",
    "        node_sizes = [1500 for _ in pitch_classes]\n",
    "        \n",
    "        # Add any missing positions for pitch classes not in circle of fifths\n",
    "        for pc in pitch_classes:\n",
    "            if pc not in pos:\n",
    "                pos[pc] = (0, 0)  # Place in center as fallback\n",
    "        \n",
    "        nodes = nx.draw_networkx_nodes(graphs[0], pos, \n",
    "                                      nodelist=list(pitch_classes),\n",
    "                                      node_size=node_sizes, \n",
    "                                      node_color=node_color_list, \n",
    "                                      edgecolors=\"black\", \n",
    "                                      linewidths=1.5, \n",
    "                                      alpha=0.9)\n",
    "        \n",
    "        # Calculate angle offsets to avoid edge overlap in overlay mode\n",
    "        rad_offset = 0.15 / len(pc_transitions_list)\n",
    "        rad_start = -0.15 if len(pc_transitions_list) > 1 else 0\n",
    "        \n",
    "        # Draw edges for each transition set\n",
    "        legend_elements = []\n",
    "        threshold = 0.1  # Threshold for edge labels\n",
    "        \n",
    "        for i, (G, color) in enumerate(zip(graphs, current_colors)):\n",
    "            # Alternate the curve direction for better visualization when overlaid\n",
    "            rad = rad_start + i * rad_offset * 2\n",
    "            \n",
    "            # Draw edges with arrows\n",
    "            edge_weights = [d['weight'] * 4 + 0.5 for _, _, d in G.edges(data=True)]\n",
    "            if edge_weights:  # Check if there are any edges\n",
    "                edges = nx.draw_networkx_edges(\n",
    "                    G, pos, width=edge_weights, \n",
    "                    alpha=0.7, edge_color=color, \n",
    "                    connectionstyle=f'arc3,rad={rad}',  # Curved edges\n",
    "                    arrowstyle='-|>',  # Arrow style\n",
    "                    arrowsize=20       # Arrow size\n",
    "                )\n",
    "            \n",
    "            # Create edge labels\n",
    "            edge_labels = {(u, v): f\"{d['weight']:.2f}\" \n",
    "                          for u, v, d in G.edges(data=True) \n",
    "                          if d['weight'] > threshold}\n",
    "            \n",
    "            # Position labels with slight offset based on the graph\n",
    "            pos_labels = {k: (v[0] * (1 + 0.05 * i), v[1] * (1 + 0.05 * i)) for k, v in pos.items()}\n",
    "            \n",
    "            # Only draw edge labels if there are any meeting the threshold\n",
    "            if edge_labels:\n",
    "                nx.draw_networkx_edge_labels(\n",
    "                    G, pos_labels, edge_labels=edge_labels, \n",
    "                    font_size=12, font_color=color,\n",
    "                    label_pos=0.5 + 0.1 * i  # Adjust position along edge\n",
    "                )\n",
    "            \n",
    "            # Add to legend\n",
    "            legend_elements.append(\n",
    "                plt.Line2D([0], [0], color=color, lw=4, marker='>', markersize=10, label=current_labels[i])\n",
    "            )\n",
    "        \n",
    "        # Add node labels\n",
    "        nx.draw_networkx_labels(graphs[0], pos, font_size=16, font_weight=\"bold\", font_color=\"black\")\n",
    "        \n",
    "        # Add legend\n",
    "        plt.legend(handles=legend_elements, loc='upper right', fontsize=14)\n",
    "        \n",
    "        plt.title(current_title, fontsize=18)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if current_save_path:\n",
    "            plt.savefig(current_save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return graphs, pos, pc_transitions_list\n",
    "    \n",
    "    # Create plots based on plot_type\n",
    "    if plot_type == 'overlay':\n",
    "        # Single plot with all transitions\n",
    "        current_title = title if isinstance(title, str) else \"Pitch Transition Network\"\n",
    "        current_save = save_path if isinstance(save_path, str) or save_path is None else save_path[0]\n",
    "        result = create_plot(all_pc_transitions, labels, edge_colors, current_title, current_save)\n",
    "        return result\n",
    "    \n",
    "    elif plot_type == 'individual':\n",
    "        # Individual plots for each transition set\n",
    "        results = []\n",
    "        titles = title if isinstance(title, list) else [f\"{title}\\n{labels[i]} Transitions\" for i in range(n_networks)]\n",
    "        save_paths = save_path if isinstance(save_path, list) or save_path is None else [save_path] * n_networks\n",
    "        \n",
    "        for i, pc_trans in enumerate(all_pc_transitions):\n",
    "            current_title = titles[i]\n",
    "            current_save = None if save_paths is None else save_paths[i]\n",
    "            result = create_plot([pc_trans], [labels[i]], [edge_colors[i]], current_title, current_save)\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"plot_type must be either 'overlay' or 'individual'\")\n",
    "\n",
    "def visualize_strongest_trans_mod(transitions_tuple, \n",
    "                                  threshold=0.15, \n",
    "                                  plot_type='overlay',\n",
    "                                  title=None,\n",
    "                                  labels=None):\n",
    "    \"\"\"\n",
    "    Create a network graph showing only the strongest octave-modulo transitions above a threshold.\n",
    "    \n",
    "    Parameters:\n",
    "        transitions_tuple (tuple): Tuple of dictionaries in the order:\n",
    "                                  (chromatic, diatonic, third, fourth, fifth, sixth, seventh, octave)\n",
    "        threshold (float): Minimum probability to include (0.0-1.0)\n",
    "        plot_type (str): Either 'overlay' to show all transitions on one plot or 'individual' for separate plots\n",
    "        title (str or None): Custom title for the plot. If None, a default title will be generated\n",
    "        labels (list or None): Custom labels for each transition type. If None, default labels will be used\n",
    "    Returns:\n",
    "        None: Displays the plot(s) and returns nothing\n",
    "    \"\"\"\n",
    "    # Default labels if none provided\n",
    "    default_labels = ['Chromatic', 'Diatonic', 'Third', 'Fourth', 'Fifth', 'Sixth', 'Seventh', 'Octave']\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = default_labels\n",
    "    \n",
    "    # Convert tuple to dictionary with labels\n",
    "    transitions_dict = {}\n",
    "    for i, trans_dict in enumerate(transitions_tuple):\n",
    "        if i < len(labels):  # Ensure we have a label for this transition\n",
    "            transitions_dict[labels[i]] = trans_dict\n",
    "    \n",
    "    # Filter strong transitions for each set\n",
    "    strong_transitions = {}\n",
    "    for label, transition_probs in transitions_dict.items():\n",
    "        strong_transitions[label] = {k: v for k, v in transition_probs.items() if v >= threshold}\n",
    "    \n",
    "    # Generate default title if none provided\n",
    "    default_title = f\"Strongest Transitions (Probability > {threshold})\"\n",
    "    plot_title = title if title is not None else default_title\n",
    "    \n",
    "    # For overlay plot - show all transitions on a single plot\n",
    "    if plot_type == 'overlay':\n",
    "        if any(strong_transitions.values()):  # Only if we have some strong transitions\n",
    "            visualize_pitch_trans_mod(\n",
    "                list(strong_transitions.values()),  # Pass list of transition dictionaries\n",
    "                plot_type='overlay',\n",
    "                title=plot_title,\n",
    "                labels=list(strong_transitions.keys())  # Pass the labels\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No transitions with probability >= {threshold} found\")\n",
    "    \n",
    "    # For individual plots - create a separate plot for each transition set\n",
    "    elif plot_type == 'individual':\n",
    "        for label, transition_probs in strong_transitions.items():\n",
    "            if transition_probs:  # Only create plot if there are strong transitions\n",
    "                # For individual plots, append the label to the title if not custom\n",
    "                indiv_title = f\"{label}: {plot_title}\" if title is not None else f\"{label}: Strongest Transitions (Probability > {threshold})\"\n",
    "                visualize_pitch_trans_mod(\n",
    "                    [transition_probs],  # Pass as a list with single dictionary\n",
    "                    plot_type='overlay',  # Use overlay for a single plot\n",
    "                    title=indiv_title,\n",
    "                    labels=[label]  # Pass the single label\n",
    "                )\n",
    "            else:\n",
    "                print(f\"No transitions with probability >= {threshold} found for {label}\")\n",
    "    else:\n",
    "        print(f\"Invalid plot_type: {plot_type}. Please use 'overlay' or 'individual'\")\n",
    "\n",
    "def count_interval_edges(data_transitions, probability_threshold=0.0):\n",
    "    \"\"\"\n",
    "    Count the number of edges for each interval type based on the transitions data.\n",
    "    \n",
    "    Parameters:\n",
    "    data_transitions (dict): The transitions data used by create_static_pitch_class_graph2\n",
    "    probability_threshold (float): Minimum probability for transitions to be counted\n",
    "    \n",
    "    Returns:\n",
    "    counts (dict): A dictionary with counts of edges for each interval type\n",
    "    \"\"\"\n",
    "    # We need to use the same function to create the modulo transitions\n",
    "    # This is referenced in the original code but not defined there\n",
    "    # Let's assume it's available and use it\n",
    "    chromatic_pc, diatonic_pc, thirds_pc, fourths_pc, fifths_pc, sixths_pc, sevenths_pc, octave_pc = data_transitions\n",
    "        \n",
    "    # Define transition types and their corresponding dictionaries\n",
    "    transition_types = {\n",
    "        'Chromatic': chromatic_pc,\n",
    "        'Diatonic': diatonic_pc,\n",
    "        'Thirds': thirds_pc,\n",
    "        'Fourths': fourths_pc,\n",
    "        'Fifths': fifths_pc,\n",
    "        'Sixths': sixths_pc,\n",
    "        'Sevenths': sevenths_pc,\n",
    "        'Octave Jump': octave_pc\n",
    "    }\n",
    "    # Initialize counts dictionary from transition_types keys\n",
    "    counts = {transition_name: 0 for transition_name in transition_types}\n",
    "\n",
    "    # Count all transitions in a single loop\n",
    "    for transition_name, transitions_dict in transition_types.items():\n",
    "        for (from_pc, to_pc), weight in transitions_dict.items():\n",
    "            if weight >= probability_threshold:\n",
    "                counts[transition_name] += 1\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def plot_interval_usage(edge_counts_list, artist_names):\n",
    "    \"\"\"\n",
    "    Convert edge counts into a DataFrame and plot interval type usage and standard deviation per artist.\n",
    "\n",
    "    Parameters:\n",
    "        edge_counts_list (list): List of dictionaries, each containing edge counts for an artist.\n",
    "        artist_names (list): List of artist names corresponding to the edge counts.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays two plots - interval type usage and standard deviation per artist.\n",
    "    \"\"\"\n",
    "    # Validate input lengths\n",
    "    if len(edge_counts_list) != len(artist_names):\n",
    "        raise ValueError(\"Length of edge_counts_list must match length of artist_names\")\n",
    "\n",
    "    # Define interval types based on the keys in the dictionaries\n",
    "    interval_types = sorted(set().union(*[set(d.keys()) for d in edge_counts_list]))\n",
    "    \n",
    "    # Prepare data dictionary for DataFrame\n",
    "    data = {'Artist': artist_names}\n",
    "    for interval in interval_types:\n",
    "        data[interval] = [edge_counts.get(interval, 0) for edge_counts in edge_counts_list]\n",
    "\n",
    "    # Create DataFrame and set Artist as index\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('Artist', inplace=True)\n",
    "\n",
    "    # Plot 1: Interval Type Usage by Artist\n",
    "    ax = df.plot(kind='bar', figsize=(12, 6), width=0.8)\n",
    "    plt.title('Interval Type Usage by Artist')\n",
    "    plt.xlabel('Artist')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(title='Interval Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate standard deviation for each artist\n",
    "    std_devs = df.std(axis=1).sort_values(ascending=False)\n",
    "\n",
    "    # Plot 2: Standard Deviation of Interval Usage per Artist\n",
    "    std_devs.plot(kind='bar', figsize=(10, 6))\n",
    "    plt.title('Interval Type Usage Variance per Artist')\n",
    "    plt.xlabel('Artist')\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# for interval types save labels here\n",
    "labels = ['Chromatic', 'Diatonic', 'Third', 'Fourth', 'Fifth', 'Sixth', 'Seventh', 'Octave']\n",
    "\n",
    "#### probability transition matrices heatmap, simulations not used ####\n",
    "def build_transition_matrix(transition_probs):\n",
    "    \"\"\"\n",
    "    Build a transition matrix from a dictionary of transition probabilities.\n",
    "\n",
    "    Parameters:\n",
    "        transition_probs (dict): Dictionary with (from_pitch, to_pitch) tuples as keys and probabilities as values.\n",
    "\n",
    "    Returns:\n",
    "        (P, states) (tuple):\n",
    "            - P (numpy.ndarray): Transition matrix.\n",
    "            - states (list): List of unique pitch values.\n",
    "    \"\"\"\n",
    "    # Extract unique pitches\n",
    "    unique_pitches = set()\n",
    "    for from_pitch, to_pitch in transition_probs.keys():\n",
    "        unique_pitches.add(from_pitch)\n",
    "        unique_pitches.add(to_pitch)\n",
    "    \n",
    "    # Sort pitches for consistent ordering\n",
    "    states = sorted(list(unique_pitches))\n",
    "    n = len(states)\n",
    "    \n",
    "    # Create mapping from pitch to index\n",
    "    pitch_to_index = {pitch: i for i, pitch in enumerate(states)}\n",
    "    \n",
    "    # Initialize transition matrix with zeros\n",
    "    P = np.zeros((n, n))\n",
    "    \n",
    "    # Fill the transition matrix\n",
    "    for (from_pitch, to_pitch), prob in transition_probs.items():\n",
    "        i = pitch_to_index[from_pitch]\n",
    "        j = pitch_to_index[to_pitch]\n",
    "        P[i, j] = prob\n",
    "    \n",
    "    # Ensure rows sum to 1 (handle missing transitions)\n",
    "    row_sums = P.sum(axis=1)\n",
    "    for i in range(n):\n",
    "        if row_sums[i] > 0:\n",
    "            P[i, :] /= row_sums[i]\n",
    "    \n",
    "    return P, states\n",
    "\n",
    "def compute_steady_state(P, max_iterations=1000, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the steady state distribution of a Markov chain.\n",
    "\n",
    "    Parameters:\n",
    "        P (numpy.ndarray): Transition matrix.\n",
    "        max_iterations (int): Maximum number of iterations (default: 1000).\n",
    "        tolerance (float): Convergence tolerance (default: 1e-6).\n",
    "\n",
    "    Returns:\n",
    "        steady_state, iterations, converged (tuple): \n",
    "            - steady_state (array): Steady state distribution if converged, None otherwise.\n",
    "            - iterations (int): Number of iterations performed.\n",
    "            - converged (bool): Whether the algorithm converged.\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Initialize with uniform distribution\n",
    "    pi = np.ones(n) / n\n",
    "    \n",
    "    # Power iteration\n",
    "    for i in range(max_iterations):\n",
    "        pi_next = pi @ P\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.max(np.abs(pi_next - pi)) < tolerance:\n",
    "            return pi_next, i+1, True\n",
    "        \n",
    "        pi = pi_next\n",
    "    \n",
    "    return pi, max_iterations, False\n",
    "\n",
    "def analyze_markov_chain(transition_probs, show_heatmap=False, show_plot=False, artist_name=None):\n",
    "    \"\"\"\n",
    "    Analyze a Markov chain defined by transition probabilities.\n",
    "\n",
    "    Parameters:\n",
    "        transition_probs (dict): Dictionary with (from_pitch, to_pitch) tuples as keys and probabilities as values.\n",
    "        show_heatmap (bool): Whether to plot the transition matrix heatmap (default: False).\n",
    "        show_plot (bool): Whether to plot the steady state distribution (default: False).\n",
    "        artist_name (str): Name of the artist for output (default: None).\n",
    "\n",
    "    Returns:\n",
    "        P, states, steady_state (tuple):\n",
    "            - P (array): Transition matrix.\n",
    "            - states (list): List of states (MIDI notes).\n",
    "            - steady_state (dict): Dictionary mapping pitch to steady state probability.\n",
    "    \"\"\"\n",
    "    # Build transition matrix\n",
    "    P, states = build_transition_matrix(transition_probs)\n",
    "    \n",
    "    print(f\"\\n{'=' * 20} {artist_name if artist_name else 'Artist'} {'=' * 20}\")\n",
    "    \n",
    "    # Print a more interpretable version of the transition matrix\n",
    "    print(f\"States (MIDI notes): {states}\")\n",
    "    print(f\"Matrix shape: {P.shape[0]} x {P.shape[1]}\")\n",
    "    \n",
    "    # Either print a small sample of the matrix or visualize it\n",
    "    if len(states) <= 10:\n",
    "        # If matrix is small enough, print it with labeled rows and columns\n",
    "        print(\"\\nFull Transition Matrix:\")\n",
    "        row_format = \"{:>5}\" + \"{:>8}\" * len(states)\n",
    "        print(row_format.format(\"\", *[f\"{s}\" for s in states]))\n",
    "        for i, row in enumerate(P):\n",
    "            print(row_format.format(f\"{states[i]}\", *[f\"{x:.3f}\" for x in row]))\n",
    "    else:\n",
    "        # If matrix is large, print a sample from the center of the matrix\n",
    "        print(\"\\nSample of Transition Matrix (central portion):\")\n",
    "        center = len(states) // 2\n",
    "        sample_size = min(5, len(states) // 2)\n",
    "        sample_start = max(0, center - sample_size)\n",
    "        sample_end = min(len(states), center + sample_size + 1)\n",
    "        \n",
    "        # Print column headers (MIDI notes)\n",
    "        row_format = \"{:>5}\" + \"{:>8}\" * (sample_end - sample_start)\n",
    "        sample_states = states[sample_start:sample_end]\n",
    "        print(row_format.format(\"\", *[f\"{s}\" for s in sample_states]))\n",
    "        \n",
    "        # Print sample rows with row headers\n",
    "        for i in range(sample_start, sample_end):\n",
    "            print(row_format.format(f\"{states[i]}\", *[f\"{P[i,j]:.3f}\" for j in range(sample_start, sample_end)]))\n",
    "    \n",
    "    # Create a heatmap visualization of the transition matrix if requested\n",
    "    if show_heatmap:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(P, cmap='Blues')\n",
    "        plt.colorbar(label='Transition Probability')\n",
    "        plt.title(f'Transition Matrix for {artist_name if artist_name else \"Artist\"}')\n",
    "        \n",
    "        # Add tick labels (may be too crowded for large matrices)\n",
    "        if len(states) <= 20:\n",
    "            plt.xticks(range(len(states)), states, rotation=90)\n",
    "            plt.yticks(range(len(states)), states)\n",
    "        else:\n",
    "            # For larger matrices, show fewer ticks\n",
    "            tick_step = len(states) // 10\n",
    "            plt.xticks(range(0, len(states), tick_step), [states[i] for i in range(0, len(states), tick_step)], rotation=90)\n",
    "            plt.yticks(range(0, len(states), tick_step), [states[i] for i in range(0, len(states), tick_step)])\n",
    "        \n",
    "        plt.xlabel('To MIDI Note')\n",
    "        plt.ylabel('From MIDI Note')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Compute steady state distribution\n",
    "    pi, iterations, converged = compute_steady_state(P)\n",
    "    \n",
    "    # Create result dictionary\n",
    "    steady_state = {pitch: prob for pitch, prob in zip(states, pi)}\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{artist_name if artist_name else 'Artist'} - Markov chain analysis completed in {iterations} iterations.\")\n",
    "    if converged:\n",
    "        print(f\"{artist_name if artist_name else 'Artist'} - Steady state distribution converged.\")\n",
    "    else:\n",
    "        print(f\"{artist_name if artist_name else 'Artist'} - Warning: Steady state distribution did not converge.\")\n",
    "    \n",
    "    # Find most likely pitch\n",
    "    most_likely_pitch = states[np.argmax(pi)]\n",
    "    print(f\"{artist_name if artist_name else 'Artist'} - Most likely pitch in steady state: {most_likely_pitch} (MIDI note)\")\n",
    "    \n",
    "    # Plot steady state distribution if requested\n",
    "    if show_plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(states, pi)\n",
    "        plt.xlabel('Pitch (MIDI note)')\n",
    "        plt.ylabel('Steady State Probability')\n",
    "        plt.title(f'Steady State Distribution for {artist_name if artist_name else \"Artist\"}')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return P, states, steady_state\n",
    "\n",
    "def simulate_markov_process(P, states, num_simulations=100, num_steps=1000, initial_state=None):\n",
    "    \"\"\"\n",
    "    Simulate a Markov process multiple times and compute the average state distribution.\n",
    "\n",
    "    Parameters:\n",
    "        P (numpy.ndarray): Transition matrix.\n",
    "        states (list): List of states (MIDI notes).\n",
    "        num_simulations (int): Number of simulations to run (default: 100).\n",
    "        num_steps (int): Number of steps in each simulation (default: 1000).\n",
    "        initial_state (int): Initial state index (default: None, chosen randomly).\n",
    "\n",
    "    Returns:\n",
    "        avg_distribution (array): Average state distribution after simulations.\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    state_counts = np.zeros(n)\n",
    "    \n",
    "    for _ in range(num_simulations):\n",
    "        # Choose initial state (random if not specified)\n",
    "        current_state = initial_state if initial_state is not None else np.random.choice(n)\n",
    "        \n",
    "        # Run simulation for specified number of steps\n",
    "        for _ in range(num_steps):\n",
    "            # Transition to next state based on transition probabilities\n",
    "            current_state = np.random.choice(n, p=P[current_state])\n",
    "            \n",
    "            # Only count states after some warm-up period (e.g., last 20% of steps)\n",
    "            if _ >= 0.8 * num_steps:\n",
    "                state_counts[current_state] += 1\n",
    "    \n",
    "    # Normalize to get distribution\n",
    "    total_counts = np.sum(state_counts)\n",
    "    if total_counts > 0:\n",
    "        avg_distribution = state_counts / total_counts\n",
    "    else:\n",
    "        avg_distribution = np.ones(n) / n  # Fallback to uniform if no counts\n",
    "    \n",
    "    return avg_distribution\n",
    "\n",
    "def run_multiple_simulations(transition_probs, num_simulations=100, num_steps=1000, show_final_plot=True, artist_name=None):\n",
    "    \"\"\"\n",
    "    Run multiple Markov process simulations and compare with theoretical steady state.\n",
    "\n",
    "    Parameters:\n",
    "        transition_probs (dict): Dictionary with (from_pitch, to_pitch) tuples as keys and probabilities as values.\n",
    "        num_simulations (int): Number of simulations to run (default: 100).\n",
    "        num_steps (int): Number of steps in each simulation (default: 1000).\n",
    "        show_final_plot (bool): Whether to plot the final comparison (default: True).\n",
    "        artist_name (str): Name of the artist for output (default: None).\n",
    "\n",
    "    Returns:\n",
    "        P, states, theoretical_dist, simulated_dist (tuple):\n",
    "            - P (numpy.ndarray): Transition matrix.\n",
    "            - states (list): List of states (MIDI notes).\n",
    "            - theoretical_dist (dict): Theoretical steady state probabilities.\n",
    "            - simulated_dist (dict): Simulated steady state probabilities.\n",
    "    \"\"\"\n",
    "    # First analyze the Markov chain to get transition matrix and theoretical steady state\n",
    "    P, states, theoretical_dist = analyze_markov_chain(transition_probs, show_heatmap=False, show_plot=False, artist_name=artist_name)\n",
    "    \n",
    "    # Run simulations\n",
    "    print(f\"\\nRunning {num_simulations} simulations with {num_steps} steps each for {artist_name if artist_name else 'Artist'}...\")\n",
    "    avg_distribution = simulate_markov_process(P, states, num_simulations, num_steps)\n",
    "    \n",
    "    # Create simulated distribution dictionary\n",
    "    simulated_dist = {pitch: prob for pitch, prob in zip(states, avg_distribution)}\n",
    "    \n",
    "    # Extract theoretical probabilities for comparison\n",
    "    theoretical_probs = np.array([theoretical_dist[state] for state in states])\n",
    "    \n",
    "    # Calculate mean absolute error between theoretical and simulated\n",
    "    mae = np.mean(np.abs(theoretical_probs - avg_distribution))\n",
    "    \n",
    "    print(f\"{artist_name if artist_name else 'Artist'} - Mean absolute error between theoretical and simulated: {mae:.6f}\")\n",
    "    \n",
    "    # Plot comparison if requested\n",
    "    if show_final_plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        x = np.arange(len(states))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, theoretical_probs, width, label='Theoretical', alpha=0.7)\n",
    "        plt.bar(x + width/2, avg_distribution, width, label='Simulated', alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('Pitch (MIDI note)')\n",
    "        plt.ylabel('Steady State Probability')\n",
    "        plt.title(f'Theoretical vs Simulated Steady State for {artist_name if artist_name else \"Artist\"}')\n",
    "        plt.xticks(x, states, rotation=90)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Also show heatmap of transition matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(P, cmap='Blues')\n",
    "        plt.colorbar(label='Transition Probability')\n",
    "        plt.title(f'Transition Matrix for {artist_name if artist_name else \"Artist\"}')\n",
    "        \n",
    "        # Add tick labels (may be too crowded for large matrices)\n",
    "        if len(states) <= 20:\n",
    "            plt.xticks(range(len(states)), states, rotation=90)\n",
    "            plt.yticks(range(len(states)), states)\n",
    "        else:\n",
    "            # For larger matrices, show fewer ticks\n",
    "            tick_step = len(states) // 10\n",
    "            plt.xticks(range(0, len(states), tick_step), [states[i] for i in range(0, len(states), tick_step)], rotation=90)\n",
    "            plt.yticks(range(0, len(states), tick_step), [states[i] for i in range(0, len(states), tick_step)])\n",
    "        \n",
    "        plt.xlabel('To MIDI Note')\n",
    "        plt.ylabel('From MIDI Note')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return P, states, theoretical_dist, simulated_dist\n",
    "\n",
    "def compare_markov_chains(all_transition_probs, all_labels, show_plot=False):\n",
    "    \"\"\"\n",
    "    Compare steady state distributions of multiple Markov chains.\n",
    "\n",
    "    Parameters:\n",
    "        all_transition_probs (list): List of transition probability dictionaries.\n",
    "        all_labels (list): List of labels for each transition probability dictionary.\n",
    "        show_plot (bool): Whether to plot the comparison (default: False).\n",
    "\n",
    "    Returns:\n",
    "        all_steady_states, all_matrices, all_states_lists (tuple):\n",
    "            - all_steady_states (list): List of (steady_state, label) tuples.\n",
    "            - all_matrices (list): List of transition matrices.\n",
    "            - all_states_lists (list): List of state lists.\n",
    "    \"\"\"\n",
    "    if show_plot:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Define a color map for multiple artists\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(all_transition_probs)))\n",
    "    \n",
    "    # Track all pitches across all artists\n",
    "    all_pitches = set()\n",
    "    all_steady_states = []\n",
    "    all_matrices = []\n",
    "    all_states_lists = []\n",
    "    \n",
    "    # Compute steady states for each artist\n",
    "    for i, (transition_probs, label) in enumerate(zip(all_transition_probs, all_labels)):\n",
    "        # Extract artist name from label (assuming format \"Moanin - ArtistName\")\n",
    "        artist_name = label.split(\" - \")[1] if \" - \" in label else label\n",
    "        \n",
    "        P, states, steady_state = analyze_markov_chain(transition_probs, show_heatmap=False, show_plot=False, artist_name=artist_name)\n",
    "        all_steady_states.append((steady_state, label))\n",
    "        all_matrices.append(P)\n",
    "        all_states_lists.append(states)\n",
    "        all_pitches.update(steady_state.keys())\n",
    "    \n",
    "    # Sort pitches for consistent x-axis\n",
    "    all_pitches = sorted(list(all_pitches))\n",
    "    \n",
    "    # Plot steady states for each artist if requested\n",
    "    if show_plot:\n",
    "        # First plot the bar chart comparison\n",
    "        bar_width = 0.8 / len(all_transition_probs)\n",
    "        for i, (steady_state, label) in enumerate(all_steady_states):\n",
    "            # Fill in missing pitches with zeros\n",
    "            probs = [steady_state.get(pitch, 0) for pitch in all_pitches]\n",
    "            \n",
    "            # Calculate bar positions\n",
    "            positions = np.array(all_pitches) + (i - len(all_transition_probs)/2 + 0.5) * bar_width\n",
    "            \n",
    "            plt.bar(positions, probs, width=bar_width, color=colors[i], label=label, alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('Pitch (MIDI note)')\n",
    "        plt.ylabel('Steady State Probability')\n",
    "        plt.title('Comparison of Steady State Distributions')\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Now plot all heatmaps in a row\n",
    "        n_artists = len(all_transition_probs)\n",
    "        fig, axes = plt.subplots(1, n_artists, figsize=(5*n_artists, 6))\n",
    "        \n",
    "        # If there's only one artist, axes won't be an array\n",
    "        if n_artists == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, (P, states, (_, label)) in enumerate(zip(all_matrices, all_states_lists, all_steady_states)):\n",
    "            artist_name = label.split(\" - \")[1] if \" - \" in label else label\n",
    "            im = axes[i].imshow(P, cmap='Blues')\n",
    "            axes[i].set_title(f'{artist_name}')\n",
    "            \n",
    "            # Add tick labels (may be too crowded for large matrices)\n",
    "            if len(states) <= 10:\n",
    "                axes[i].set_xticks(range(len(states)))\n",
    "                axes[i].set_xticklabels(states, rotation=90)\n",
    "                axes[i].set_yticks(range(len(states)))\n",
    "                axes[i].set_yticklabels(states)\n",
    "            else:\n",
    "                # For larger matrices, show fewer ticks\n",
    "                tick_step = len(states) // 5\n",
    "                axes[i].set_xticks(range(0, len(states), tick_step))\n",
    "                axes[i].set_xticklabels([states[j] for j in range(0, len(states), tick_step)], rotation=90)\n",
    "                axes[i].set_yticks(range(0, len(states), tick_step))\n",
    "                axes[i].set_yticklabels([states[j] for j in range(0, len(states), tick_step)])\n",
    "            \n",
    "            # Only add y-label for the first subplot\n",
    "            if i == 0:\n",
    "                axes[i].set_ylabel('From MIDI Note')\n",
    "            \n",
    "            axes[i].set_xlabel('To MIDI Note')\n",
    "        \n",
    "        # Add a colorbar\n",
    "        fig.subplots_adjust(right=0.9)\n",
    "        cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "        fig.colorbar(im, cax=cbar_ax, label='Transition Probability')\n",
    "        \n",
    "        plt.suptitle('Transition Matrices for All Artists', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 0.95])  # Adjust the rect to leave space for the colorbar\n",
    "        plt.show()\n",
    "    \n",
    "    return all_steady_states, all_matrices, all_states_lists\n",
    "\n",
    "def run_all_simulations(midi_files, num_simulations=100, num_steps=1000, show_individual_plots=True, show_comparison=True):\n",
    "    \"\"\"\n",
    "    Run simulations for all artists and compare their steady state distributions.\n",
    "\n",
    "    Parameters:\n",
    "        midi_files (list): List of (artist_name, midi_data) tuples.\n",
    "        num_simulations (int): Number of simulations per artist (default: 100).\n",
    "        num_steps (int): Number of steps per simulation (default: 1000).\n",
    "        show_individual_plots (bool): Whether to show individual artist plots (default: True).\n",
    "        show_comparison (bool): Whether to show comparison plot of all artists (default: True).\n",
    "\n",
    "    Returns:\n",
    "        all_theoretical_dists, all_simulated_dists, all_matrices, all_states_lists (tuple):\n",
    "            - all_theoretical_dists (list): List of (theoretical_dist, label) tuples.\n",
    "            - all_simulated_dists (list): List of (simulated_dist, label) tuples.\n",
    "            - all_matrices (list): List of transition matrices.\n",
    "            - all_states_lists (list): List of state lists.\n",
    "    \"\"\"\n",
    "    all_transition_probs = []\n",
    "    all_labels = []\n",
    "    all_theoretical_dists = []\n",
    "    all_simulated_dists = []\n",
    "    all_matrices = []\n",
    "    all_states_lists = []\n",
    "\n",
    "    for artist, midi_file in midi_files:\n",
    "        transition_probs, _, _ = get_prob_transitions(midi_file)\n",
    "\n",
    "        # Add this line to run ergodicity analysis\n",
    "        P, states, ergodicity_results = integrate_with_existing_code(transition_probs, artist_name=artist.capitalize())\n",
    "        \n",
    "        all_transition_probs.append(transition_probs)\n",
    "        label = f\"Moanin - {artist.capitalize()}\"\n",
    "        all_labels.append(label)\n",
    "        \n",
    "        # Run simulations for this artist\n",
    "        P, states, theoretical_dist, simulated_dist = run_multiple_simulations(\n",
    "            transition_probs,\n",
    "            num_simulations=num_simulations,\n",
    "            num_steps=num_steps,\n",
    "            show_final_plot=show_individual_plots,\n",
    "            artist_name=artist.capitalize()\n",
    "        )\n",
    "        \n",
    "        all_theoretical_dists.append((theoretical_dist, label))\n",
    "        all_simulated_dists.append((simulated_dist, label))\n",
    "        all_matrices.append(P)\n",
    "        all_states_lists.append(states)\n",
    "\n",
    "    # Compare all artists if requested\n",
    "    if show_comparison:\n",
    "        print(\"\\nComparing theoretical steady states across all artists:\")\n",
    "        all_steady_states, _, _ = compare_markov_chains(all_transition_probs, all_labels, show_plot=True)\n",
    "        \n",
    "        print(\"\\nMost likely notes for each artist:\")\n",
    "        for (steady_state, label) in all_theoretical_dists:\n",
    "            # Extract artist name\n",
    "            artist_name = label.split(\" - \")[1] if \" - \" in label else label\n",
    "            \n",
    "            # Sort by probability (descending)\n",
    "            sorted_notes = sorted(steady_state.items(), key=lambda x: x[1], reverse=True)\n",
    "            top_notes = sorted_notes[:3]\n",
    "            \n",
    "            print(f\"\\n{artist_name}:\")\n",
    "            for note, prob in top_notes:\n",
    "                print(f\"  MIDI note {note}/{midi_to_pitch_class(note)}: {prob:.4f} probability\")\n",
    "    \n",
    "    return all_theoretical_dists, all_simulated_dists, all_matrices, all_states_lists\n",
    "\n",
    "#### check ergodicity of transition matrix, this was not used ####\n",
    "def is_irreducible(P, tolerance=1e-10):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain transition matrix is irreducible.\n",
    "\n",
    "    Parameters:\n",
    "        P (array): Transition matrix.\n",
    "        tolerance (float): Numerical tolerance for considering a probability non-zero (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the Markov chain is irreducible, False otherwise.\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Compute P^1 + P^2 + ... + P^n\n",
    "    # If all states can reach all other states, this sum will have all non-zero entries\n",
    "    P_sum = np.copy(P)\n",
    "    P_power = np.copy(P)\n",
    "    \n",
    "    for _ in range(2, n+1):\n",
    "        P_power = P_power @ P\n",
    "        P_sum += P_power\n",
    "    \n",
    "    # Check if any entry is zero (or very close to zero)\n",
    "    return np.all(P_sum > tolerance)\n",
    "\n",
    "def get_period(P, state, tolerance=1e-10):\n",
    "    \"\"\"\n",
    "    Calculate the period of a specific state in a Markov chain.\n",
    "\n",
    "    Parameters:\n",
    "        P (array): Transition matrix.\n",
    "        state (int): Index of the state to check.\n",
    "        tolerance (float): Numerical tolerance for considering a probability non-zero (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "        period (int): Period of the state, or 0 if the state doesn't return to itself.\n",
    "    \"\"\"\n",
    "    # Keep track of when we can return to the starting state\n",
    "    return_times = []\n",
    "    \n",
    "    # Compute P^k for k=1,2,...,n and check return probabilities\n",
    "    P_power = np.copy(P)\n",
    "    \n",
    "    for k in range(1, P.shape[0] + 1):\n",
    "        if P_power[state, state] > tolerance:\n",
    "            return_times.append(k)\n",
    "        P_power = P_power @ P\n",
    "    \n",
    "    if not return_times:\n",
    "        return 0  # State doesn't return to itself\n",
    "    \n",
    "    # Period is the GCD of all return times\n",
    "    period = return_times[0]\n",
    "    for t in return_times[1:]:\n",
    "        period = np.gcd(period, t)\n",
    "    \n",
    "    return period\n",
    "\n",
    "def is_aperiodic(P, tolerance=1e-10):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain transition matrix is aperiodic.\n",
    "\n",
    "    Parameters:\n",
    "        P (array): Transition matrix.\n",
    "        tolerance (float): Numerical tolerance for considering a probability non-zero (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the Markov chain is aperiodic, False otherwise.\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Alternative approach: If P has a self-loop (P[i,i] > 0), it's aperiodic\n",
    "    # Check if any state has a self-transition\n",
    "    for i in range(n):\n",
    "        if P[i, i] > tolerance:\n",
    "            return True\n",
    "    \n",
    "    # If no self-loops, compute the period for each state\n",
    "    for i in range(n):\n",
    "        period = get_period(P, i, tolerance)\n",
    "        if period == 1:\n",
    "            return True  # Found a state with period 1, so chain is aperiodic\n",
    "        elif period == 0:\n",
    "            continue  # This state doesn't return to itself\n",
    "    \n",
    "    return False  # No state with period 1 found, chain is periodic\n",
    "\n",
    "def is_ergodic(P, tolerance=1e-10):\n",
    "    \"\"\"\n",
    "    Check if a Markov chain transition matrix is ergodic.\n",
    "\n",
    "    Parameters:\n",
    "        P (array): Transition matrix.\n",
    "        tolerance (float): Numerical tolerance for considering a probability non-zero (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "        ergodic, info (tuple):\n",
    "            - ergodic (bool): True if the Markov chain is ergodic, False otherwise.\n",
    "            - info (dict): Dictionary with 'irreducible', 'aperiodic', and 'ergodic' keys.\n",
    "    \"\"\"\n",
    "    irreducible_result = is_irreducible(P, tolerance)\n",
    "    aperiodic_result = is_aperiodic(P, tolerance)\n",
    "    ergodic_result = irreducible_result and aperiodic_result\n",
    "    \n",
    "    info = {\n",
    "        'irreducible': irreducible_result,\n",
    "        'aperiodic': aperiodic_result,\n",
    "        'ergodic': ergodic_result\n",
    "    }\n",
    "    \n",
    "    return ergodic_result, info\n",
    "\n",
    "def eigenvalue_analysis(P, tolerance=1e-10):\n",
    "    \"\"\"\n",
    "    Analyze eigenvalues of a transition matrix to check for ergodicity.\n",
    "\n",
    "    Parameters:\n",
    "        P (array): Transition matrix.\n",
    "        tolerance (float): Numerical tolerance for eigenvalue magnitude (default: 1e-10).\n",
    "\n",
    "    Returns:\n",
    "        info (dict): Dictionary with eigenvalue analysis information including \n",
    "                    'eigenvalues', 'unit_eigenvalues', 'num_unit_eigenvalues', \n",
    "                    and 'ergodic_by_eigenvalues'.\n",
    "    \"\"\"\n",
    "    # Compute eigenvalues\n",
    "    eigenvalues = linalg.eigvals(P)\n",
    "    \n",
    "    # Count eigenvalues with magnitude close to 1\n",
    "    unit_eigenvalues = [ev for ev in eigenvalues if abs(abs(ev) - 1) < tolerance]\n",
    "    \n",
    "    info = {\n",
    "        'eigenvalues': eigenvalues,\n",
    "        'unit_eigenvalues': unit_eigenvalues,\n",
    "        'num_unit_eigenvalues': len(unit_eigenvalues),\n",
    "        'ergodic_by_eigenvalues': len(unit_eigenvalues) == 1\n",
    "    }\n",
    "    \n",
    "    return info\n",
    "\n",
    "def analyze_ergodicity(P, states=None, tolerance=1e-10, artist_name=None):\n",
    "    \"\"\"\n",
    "    Perform comprehensive ergodicity analysis on a Markov chain.\n",
    "\n",
    "    Parameters:\n",
    "        P (array): Transition matrix.\n",
    "        states (list): List of state labels (default: None).\n",
    "        tolerance (float): Numerical tolerance for tests (default: 1e-10).\n",
    "        artist_name (str): Name for output (default: None).\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary with 'ergodic', 'irreducible', 'aperiodic', and 'eigenvalue_analysis' results.\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    \n",
    "    # Check for ergodicity\n",
    "    is_ergodic_result, ergodic_info = is_ergodic(P, tolerance)\n",
    "    eigenvalue_info = eigenvalue_analysis(P, tolerance)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'=' * 20} Ergodicity Analysis for {artist_name if artist_name else 'Matrix'} {'=' * 20}\")\n",
    "    print(f\"Matrix size: {n} x {n}\")\n",
    "    print(f\"Irreducible: {ergodic_info['irreducible']}\")\n",
    "    print(f\"Aperiodic: {ergodic_info['aperiodic']}\")\n",
    "    print(f\"Ergodic: {ergodic_info['ergodic']}\")\n",
    "    print(f\"Number of eigenvalues with magnitude 1: {eigenvalue_info['num_unit_eigenvalues']}\")\n",
    "    print(f\"Ergodic by eigenvalue analysis: {eigenvalue_info['ergodic_by_eigenvalues']}\")\n",
    "    \n",
    "    if not ergodic_info['irreducible']:\n",
    "        print(\"Warning: The chain is not irreducible. There may be states that cannot reach other states.\")\n",
    "    \n",
    "    if not ergodic_info['aperiodic']:\n",
    "        print(\"Warning: The chain is periodic. The steady state may not be unique or convergence may not occur.\")\n",
    "    \n",
    "    # Combine all results\n",
    "    results = {\n",
    "        'ergodic': ergodic_info['ergodic'],\n",
    "        'irreducible': ergodic_info['irreducible'],\n",
    "        'aperiodic': ergodic_info['aperiodic'],\n",
    "        'eigenvalue_analysis': eigenvalue_info,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def test_example_matrices():\n",
    "    \"\"\"\n",
    "    Test ergodicity functions on example matrices.\n",
    "\n",
    "    Parameters:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        None: Prints analysis results for example matrices.\n",
    "    \"\"\"\n",
    "    # Example 1: Ergodic chain\n",
    "    P1 = np.array([\n",
    "        [0.7, 0.3],\n",
    "        [0.4, 0.6]\n",
    "    ])\n",
    "    \n",
    "    # Example 2: Reducible chain (state 1 can't reach state 0)\n",
    "    P2 = np.array([\n",
    "        [0.8, 0.2],\n",
    "        [0.0, 1.0]\n",
    "    ])\n",
    "    \n",
    "    # Example 3: Periodic chain with period 2\n",
    "    P3 = np.array([\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 0.0]\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nTesting example matrices:\")\n",
    "    analyze_ergodicity(P1, artist_name=\"Example 1 (Should be ergodic)\")\n",
    "    analyze_ergodicity(P2, artist_name=\"Example 2 (Should be reducible, not ergodic)\")\n",
    "    analyze_ergodicity(P3, artist_name=\"Example 3 (Should be periodic, not ergodic)\")\n",
    "\n",
    "def integrate_with_existing_code(transition_probs, artist_name=None):\n",
    "    \"\"\"\n",
    "    Integrate ergodicity analysis with existing transition matrix code.\n",
    "\n",
    "    Parameters:\n",
    "        transition_probs (dict): Dictionary with (from_pitch, to_pitch) tuples as keys and probabilities as values.\n",
    "        artist_name (str): Name of the artist for output (default: None).\n",
    "\n",
    "    Returns:\n",
    "        P, states, ergodicity_results (tuple):\n",
    "            - P (array): Transition matrix.\n",
    "            - states (list): List of states (MIDI notes).\n",
    "            - ergodicity_results (dict): Ergodicity analysis results.\n",
    "    \"\"\"\n",
    "    # Build transition matrix using existing function\n",
    "    P, states = build_transition_matrix(transition_probs)\n",
    "    \n",
    "    # Perform ergodicity analysis\n",
    "    ergodicity_results = analyze_ergodicity(P, states, artist_name=artist_name)\n",
    "    \n",
    "    return P, states, ergodicity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb5da9",
   "metadata": {},
   "source": [
    "### morlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce1270",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "##### all functions for molet wavelet analysis #####\n",
    "def prep_data_morlet(data_file_path, sample_rate=1000, frequencies=None, wavelet='cmor1.5-1.0', wav=False):\n",
    "    \"\"\"\n",
    "    Prepare data for Morlet wavelet analysis from MIDI or WAV files.\n",
    "\n",
    "    Parameters:\n",
    "        data_file_path (str): File path to the data (MIDI or WAV).\n",
    "        sample_rate (int): Sampling rate in Hz (default: 1000). If None, uses file's sample rate for WAV.\n",
    "        frequencies (list): List of frequencies for wavelet analysis in Hz (default: None, uses [60, 250, 500, 2000]).\n",
    "        wavelet (str): Wavelet type for transform (default: 'cmor1.5-1.0', where 1.5 is bandwidth, 1.0 is center frequency).\n",
    "        wav (bool): Whether to process a WAV file (True) or MIDI file (False) (default: False).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Depending on `wav`:\n",
    "            - If wav=True: (coefficients, _, audio_data, sample_rate, frequencies)\n",
    "            - If wav=False: (coefficients, _, time_series, velocity_series, sample_rate, frequencies)\n",
    "    \"\"\"\n",
    "    # Use default frequencies if none provided\n",
    "    if frequencies is None:\n",
    "        frequencies = np.arange(60, 2000, 10)\n",
    "    else:\n",
    "        frequencies = np.array(frequencies)\n",
    "    \n",
    "    if wav:\n",
    "        # Load the WAV file\n",
    "        file_sample_rate, audio_data = wavfile.read(data_file_path)\n",
    "        \n",
    "        # If the audio is stereo, average the channels to get mono\n",
    "        if len(audio_data.shape) > 1 and audio_data.shape[1] > 1:\n",
    "            audio_data = np.mean(audio_data, axis=1)\n",
    "            \n",
    "        # Normalize audio data to range -1 to 1 if it's int type\n",
    "        if np.issubdtype(audio_data.dtype, np.integer):\n",
    "            audio_data = audio_data.astype(np.float32) / np.iinfo(audio_data.dtype).max\n",
    "        \n",
    "        # Use the provided sample rate or the file's sample rate\n",
    "        if sample_rate is None:\n",
    "            sample_rate = file_sample_rate\n",
    "        # Resample if necessary (basic implementation - for better results use resampy or librosa)\n",
    "        elif sample_rate != file_sample_rate:\n",
    "            from scipy import signal\n",
    "            original_length = len(audio_data)\n",
    "            new_length = int(original_length * sample_rate / file_sample_rate)\n",
    "            audio_data = signal.resample(audio_data, new_length)\n",
    "    \n",
    "        # Perform Continuous Wavelet Transform (CWT) with the specified wavelet\n",
    "        coefficients, _ = pywt.cwt(audio_data, frequencies, wavelet)\n",
    "\n",
    "        return coefficients, _, audio_data, sample_rate, frequencies\n",
    "    else:\n",
    "        # Load the MIDI file\n",
    "        midi_file = pretty_midi.PrettyMIDI(data_file_path)\n",
    "\n",
    "        # Lists to hold start times and MIDI note numbers\n",
    "        start_times, note_numbers = get_midi_notes_over_time(midi_file)\n",
    "\n",
    "        # Convert to numpy arrays for sorting\n",
    "        times = np.array(start_times)\n",
    "        pitches = np.array(note_numbers)\n",
    "\n",
    "        # Sort by time\n",
    "        sorted_indices = np.argsort(times)\n",
    "        times = times[sorted_indices]\n",
    "        pitches = pitches[sorted_indices]\n",
    "        \n",
    "        # convert pitches to frequencies from (Byrd, 2007)\n",
    "        freq = [440 * (2 ** ((notes - 69) / 12)) for notes in note_numbers]\n",
    "\n",
    "        # Create a time series of velocities\n",
    "        time_series = midi_file.get_piano_roll(fs=sample_rate)\n",
    "        velocity_series = np.sum(time_series, axis=0)\n",
    "        \n",
    "        # Perform Continuous Wavelet Transform (CWT) with the specified wavelet\n",
    "        coefficients, _ = pywt.cwt(velocity_series, frequencies, wavelet)\n",
    "    \n",
    "        return coefficients, _, time_series, velocity_series, sample_rate, frequencies\n",
    "\n",
    "def get_amplitude_phase(transformed_data, wav=False):\n",
    "    \"\"\"\n",
    "    Extract amplitude and phase from wavelet-transformed data.\n",
    "\n",
    "    Parameters:\n",
    "        transformed_data (tuple): Data from prep_data_morlet (coefficients, _, audio_data/time_series, sample_rate, frequencies).\n",
    "        wav (bool): Whether the data is from a WAV file (True) or MIDI file (False) (default: False).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Depending on `wav`:\n",
    "            - If wav=True: (audio_data, sample_rate, phase, amplitude, frequencies)\n",
    "            - If wav=False: (time_series, velocity_series, sample_rate, phase, amplitude, frequencies)\n",
    "    \"\"\"\n",
    "    if wav:\n",
    "        coefficients, _, audio_data, sample_rate, frequencies = transformed_data\n",
    "\n",
    "        # Get amplitude and phase\n",
    "        amplitude = np.abs(coefficients)\n",
    "        phase = np.angle(coefficients)\n",
    "\n",
    "        return audio_data, sample_rate, phase, amplitude, frequencies\n",
    "    else:\n",
    "        coefficients, _, time_series, velocity_series, sample_rate, frequencies = transformed_data\n",
    "        # Get amplitude and phase\n",
    "        amplitude = np.abs(coefficients)\n",
    "        phase = np.angle(coefficients)\n",
    "\n",
    "        return time_series, velocity_series, sample_rate, phase, amplitude, frequencies\n",
    "\n",
    "def morlet_analysis(data_list, time_window=(0, 16), titles=None, \n",
    "                   figsize=(15, 12), wav=False):\n",
    "    \"\"\"\n",
    "    Perform and visualize Morlet wavelet analysis with waveform and spectrogram plots.\n",
    "\n",
    "    Parameters:\n",
    "        data_list (list): List of tuples from get_amplitude_phase (WAV or MIDI format).\n",
    "        time_window (tuple): Time range (start_time, end_time) in seconds (default: (0, 16)).\n",
    "        titles (list): List of titles for each dataset (default: None, uses [\"Data 1\", \"Data 2\", ...]).\n",
    "        figsize (tuple): Figure size as (width, height) (default: (15, 12)).\n",
    "        wav (bool): Whether data is from WAV files (True) or MIDI files (False) (default: False).\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Figure object containing the plots.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Validate input\n",
    "    num_datasets = len(data_list)\n",
    "    if num_datasets < 1:\n",
    "        raise ValueError(\"At least one dataset must be provided\")\n",
    "    \n",
    "    # Set default titles if none provided\n",
    "    if titles is None:\n",
    "        titles = [f\"Data {i+1}\" for i in range(num_datasets)]\n",
    "    elif len(titles) != num_datasets:\n",
    "        raise ValueError(f\"Number of titles ({len(titles)}) must match number of datasets ({num_datasets})\")\n",
    "\n",
    "    # Prepare data for each dataset\n",
    "    waveform_data = []\n",
    "    sample_rates = []\n",
    "    amplitudes = []\n",
    "    frequencies_list = []\n",
    "    \n",
    "    for i, data in enumerate(data_list):\n",
    "        if wav:\n",
    "            # WAV data format\n",
    "            audio_data, sample_rate, phase, amplitude, frequencies = data\n",
    "            waveform_data.append(audio_data)\n",
    "        else:\n",
    "            # MIDI data format\n",
    "            time_series, velocity_series, sample_rate, phase, amplitude, frequencies = data\n",
    "            waveform_data.append(velocity_series)\n",
    "        \n",
    "        sample_rates.append(sample_rate)\n",
    "        amplitudes.append(amplitude)\n",
    "        frequencies_list.append(frequencies)\n",
    "    \n",
    "    # Calculate time indices and window times for each dataset\n",
    "    time_axes = []\n",
    "    window_times = []\n",
    "    a_indices = []\n",
    "    b_indices = []\n",
    "    \n",
    "    for i in range(num_datasets):\n",
    "        time_axis = np.arange(len(waveform_data[i])) / sample_rates[i]\n",
    "        time_axes.append(time_axis)\n",
    "        \n",
    "        a = int(time_window[0] * sample_rates[i])\n",
    "        b = int(time_window[1] * sample_rates[i])\n",
    "        b = min(b, len(waveform_data[i]))  # Ensure we don't go beyond array bounds\n",
    "        \n",
    "        a_indices.append(a)\n",
    "        b_indices.append(b)\n",
    "        window_times.append(time_axis[a:b])\n",
    "    \n",
    "    # Fixed at 2 rows for waveform and spectrogram\n",
    "    num_rows = 2\n",
    "    \n",
    "    # Adjust figure size based on number of datasets\n",
    "    dynamic_figsize = (figsize[0] * num_datasets / 2, figsize[1])\n",
    "    \n",
    "    # Create figure and gridspec\n",
    "    fig = plt.figure(figsize=dynamic_figsize)\n",
    "    gs = fig.add_gridspec(num_rows, num_datasets)\n",
    "    \n",
    "    # Plot waveforms (row 0)\n",
    "    for i in range(num_datasets):\n",
    "        ax = fig.add_subplot(gs[0, i])\n",
    "        ax.plot(window_times[i], waveform_data[i][a_indices[i]:b_indices[i]])\n",
    "        ax.set_title(f'{titles[i]} Waveform')\n",
    "        \n",
    "        # Only add y-label to the first plot in each row\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Amplitude')\n",
    "    \n",
    "    # Plot spectrograms (row 1)\n",
    "    for i in range(num_datasets):\n",
    "        ax = fig.add_subplot(gs[1, i])\n",
    "        \n",
    "        # Make sure we have the right shapes for the spectrograms\n",
    "        amp_spec = amplitudes[i][:, a_indices[i]:b_indices[i]] if amplitudes[i].shape[1] >= b_indices[i] else amplitudes[i][:, a_indices[i]:amplitudes[i].shape[1]]\n",
    "        \n",
    "        # Update window_time if necessary\n",
    "        window_time_spec = window_times[i][:amp_spec.shape[1]]\n",
    "        \n",
    "        im = ax.pcolormesh(window_time_spec, frequencies_list[i], amp_spec, \n",
    "                          shading='gouraud', cmap='viridis')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(f'{titles[i]} Spectrogram')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        \n",
    "        # Only add y-label to the first plot in each row\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Frequency (Hz)')\n",
    "            \n",
    "        fig.colorbar(im, ax=ax, label='Magnitude')\n",
    "    \n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_wavelet_spectrogram(data_list, wav=False, time_window=None, titles=None, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Plot wavelet spectrograms (scalograms) for multiple datasets using continuous wavelet transform.\n",
    "\n",
    "    Parameters:\n",
    "        data_list (list): List of tuples from get_amplitude_phase (WAV or MIDI format).\n",
    "        wav (bool): Whether data is from WAV files (True) or MIDI files (False) (default: False).\n",
    "        time_window (tuple): Time range (start_time, end_time) in seconds (default: None, shows all).\n",
    "        titles (list): List of titles for each dataset (default: None, uses [\"Dataset 1\", \"Dataset 2\", ...]).\n",
    "        figsize (tuple): Figure size as (width, height) (default: (12, 6)).\n",
    "\n",
    "    Returns:\n",
    "        fig (matplotlib.figure): Figure object containing the spectrogram plots.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Handle single dataset case\n",
    "    if not isinstance(data_list, list):\n",
    "        data_list = [data_list]\n",
    "    \n",
    "    # Validate input\n",
    "    num_datasets = len(data_list)\n",
    "    if num_datasets < 1:\n",
    "        raise ValueError(\"At least one dataset must be provided\")\n",
    "    \n",
    "    # Set default titles if none provided\n",
    "    if titles is None:\n",
    "        titles = [f\"Dataset {i+1}\" for i in range(num_datasets)]\n",
    "    elif len(titles) != num_datasets:\n",
    "        raise ValueError(f\"Number of titles ({len(titles)}) must match number of datasets ({num_datasets})\")\n",
    "    \n",
    "    # Adjust figure size based on number of datasets\n",
    "    adjusted_figsize = (figsize[0] * num_datasets, figsize[1])\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig, axes = plt.subplots(1, num_datasets, figsize=adjusted_figsize)\n",
    "    \n",
    "    # Convert to array for consistent indexing, even with single dataset\n",
    "    if num_datasets == 1:\n",
    "        axes = np.array([axes])\n",
    "    \n",
    "    # Process each dataset\n",
    "    for i, (data, title, ax) in enumerate(zip(data_list, titles, axes)):\n",
    "        if wav:\n",
    "            audio_data, sample_rate, phase, amplitude, frequencies = data\n",
    "            # Compute time array from audio_data length and sample_rate\n",
    "            N = len(audio_data)\n",
    "            time = np.linspace(0, (N-1)/sample_rate, N)\n",
    "            freqs = frequencies\n",
    "        else:\n",
    "            time_series, velocity_series, sample_rate, phase, amplitude, frequencies = data\n",
    "            # Compute time array from velocity_series length and sample_rate\n",
    "            N = len(velocity_series)\n",
    "            time = np.linspace(0, (N-1)/sample_rate, N)\n",
    "            freqs = frequencies\n",
    "        \n",
    "        power = amplitude ** 2  # Compute power of coefficients\n",
    "        \n",
    "        # Set x-axis limits based on time_window parameter\n",
    "        x_min = time[0]\n",
    "        x_max = time[-1]\n",
    "        if time_window is not None:\n",
    "            start_time, end_time = time_window\n",
    "            if start_time is not None:\n",
    "                x_min = max(start_time, time[0])\n",
    "            if end_time is not None:\n",
    "                x_max = min(end_time, time[-1])\n",
    "        \n",
    "        # Plot the spectrogram\n",
    "        im = ax.imshow(power, aspect='auto', extent=[time[0], time[-1], freqs[-1], freqs[0]],\n",
    "                   cmap='inferno', interpolation='nearest')\n",
    "        \n",
    "        # Set the x-axis limits for the plot\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=ax, label=\"Power\")\n",
    "        \n",
    "        # Set labels\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        # Only add y-label to the first plot\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Frequency (Hz)\")\n",
    "        \n",
    "        ax.set_title(f\"{title}\\n({x_min:.2f}s - {x_max:.2f}s)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_amp_phase(data_list, wav=False, time_window=None, titles=None, figsize=(15, 12)):\n",
    "    \"\"\"\n",
    "    Plot amplitude and phase spectrograms for multiple datasets.\n",
    "\n",
    "    Parameters:\n",
    "        data_list (list): List of tuples from get_amplitude_phase (WAV or MIDI format).\n",
    "        wav (bool): Whether data is from WAV files (True) or MIDI files (False) (default: False).\n",
    "        time_window (tuple): Time range (start_time, end_time) in seconds (default: None, shows all).\n",
    "        titles (list): List of titles for each dataset (default: None, uses [\"Data 1\", \"Data 2\", ...]).\n",
    "        figsize (tuple): Figure size as (width, height) (default: (15, 12)).\n",
    "\n",
    "    Returns:\n",
    "        fig (matplotlib.figure): Figure object containing amplitude and phase plots.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Validate input\n",
    "    num_datasets = len(data_list)\n",
    "    if num_datasets < 1:\n",
    "        raise ValueError(\"At least one dataset must be provided\")\n",
    "    \n",
    "    # Set default titles if none provided\n",
    "    if titles is None:\n",
    "        titles = [f\"Data {i+1}\" for i in range(num_datasets)]\n",
    "    elif len(titles) != num_datasets:\n",
    "        raise ValueError(f\"Number of titles ({len(titles)}) must match number of datasets ({num_datasets})\")\n",
    "    \n",
    "    # Extract data for each dataset\n",
    "    time_axes = []\n",
    "    phases = []\n",
    "    amplitudes = []\n",
    "    frequencies_list = []\n",
    "    extents = []\n",
    "    \n",
    "    for i, data in enumerate(data_list):\n",
    "        if wav:\n",
    "            # WAV format\n",
    "            audio_data, sample_rate, phase, amplitude, frequencies = data\n",
    "            # Calculate time axis from amplitude shape\n",
    "            time_axis = np.arange(amplitude.shape[1]) / sample_rate\n",
    "        else:\n",
    "            # MIDI format\n",
    "            time_series, velocity, sample_rate, phase, amplitude, frequencies = data\n",
    "            # Calculate time axis from velocity length\n",
    "            time_axis = np.arange(len(velocity)) / sample_rate\n",
    "        \n",
    "        time_axes.append(time_axis)\n",
    "        phases.append(phase)\n",
    "        amplitudes.append(amplitude)\n",
    "        frequencies_list.append(frequencies)\n",
    "        \n",
    "        # Calculate extent (time range and frequency range)\n",
    "        # Frequencies are ordered with smallest at the bottom\n",
    "        extent = [0, time_axis[-1], frequencies[0], frequencies[-1]]\n",
    "        extents.append(extent)\n",
    "    \n",
    "    # Create a grid of subplots - 2 rows (amplitude and phase) x num_datasets columns\n",
    "    fig, axes = plt.subplots(2, num_datasets, figsize=(figsize[0] * num_datasets / 2, figsize[1]))\n",
    "    \n",
    "    # Handle the case where there's only one dataset (axes won't be 2D)\n",
    "    if num_datasets == 1:\n",
    "        axes = np.array(axes).reshape(2, 1)\n",
    "    \n",
    "    # First row: Amplitude spectrograms\n",
    "    for i in range(num_datasets):\n",
    "        im_amp = axes[0, i].imshow(amplitudes[i], extent=extents[i], aspect='auto', \n",
    "                                   cmap='viridis', origin='lower')\n",
    "        axes[0, i].set_title(f'{titles[i]} Amplitude')\n",
    "        \n",
    "        # Only add y-label to the first plot in each row\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel('Frequency (Hz)')\n",
    "            \n",
    "        axes[0, i].set_xlabel('Time (s)')\n",
    "        plt.colorbar(im_amp, ax=axes[0, i], label='Magnitude')\n",
    "        \n",
    "        # Apply time window if specified\n",
    "        if time_window is not None:\n",
    "            start_time, end_time = time_window\n",
    "            axes[0, i].set_xlim(start_time, end_time)\n",
    "    \n",
    "    # Second row: Phase spectrograms\n",
    "    for i in range(num_datasets):\n",
    "        im_phase = axes[1, i].imshow(phases[i], extent=extents[i], aspect='auto', \n",
    "                                     cmap='twilight', origin='lower')\n",
    "        axes[1, i].set_title(f'{titles[i]} Phase')\n",
    "        \n",
    "        # Only add y-label to the first plot in each row\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('Frequency (Hz)')\n",
    "            \n",
    "        axes[1, i].set_xlabel('Time (s)')\n",
    "        plt.colorbar(im_phase, ax=axes[1, i], label='Phase (radians)')\n",
    "        \n",
    "        # Apply time window if specified\n",
    "        if time_window is not None:\n",
    "            start_time, end_time = time_window\n",
    "            axes[1, i].set_xlim(start_time, end_time)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "#### dominant frequencies (which i ended up not using) ####\n",
    "def find_dominant_frequencies(amplitude, freqs, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Identify dominant frequency ranges based on wavelet coefficients.\n",
    "\n",
    "    Parameters:\n",
    "        amplitude (array): Wavelet coefficients (frequencies x time).\n",
    "        freqs (array): Array of frequency values.\n",
    "        threshold (float): Fraction of max coefficient to consider dominant (default: 0.1).\n",
    "\n",
    "    Returns:\n",
    "        dominant_freqs (array): Array of dominant frequencies.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    mean_coeffs = np.mean(np.abs(amplitude), axis=1)  # Average across time\n",
    "    max_coeff = np.max(mean_coeffs)\n",
    "\n",
    "    # coefficients are normall distributed\n",
    "    # so use 1.96 to get 95% of the data\n",
    "    threshold = np.mean(mean_coeffs) + 1.5 * np.std(mean_coeffs)\n",
    "    dominant_freqs = freqs[mean_coeffs > threshold]\n",
    "    # used to manually set this to like 0.8\n",
    "    #dominant_freqs = freqs[mean_coeffs > threshold * max_coeff]\n",
    "    \n",
    "    return dominant_freqs\n",
    "\n",
    "def plot_dominant_frequencies(freqs_list, amp_list, labels, threshold=0.1, title=None, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Plot mean wavelet coefficients and dominant frequencies for multiple datasets.\n",
    "\n",
    "    Parameters:\n",
    "        freqs_list (list): List of frequency arrays for each dataset.\n",
    "        amp_list (list): List of amplitude arrays (wavelet coefficients) for each dataset.\n",
    "        labels (list): List of labels for each dataset.\n",
    "        threshold (float): Fraction of max coefficient to consider dominant (default: 0.1).\n",
    "        title (str): Custom plot title (default: None, uses \"Dominant Frequencies Comparison\").\n",
    "        figsize (tuple): Figure size as (width, height) (default: (10, 6)).\n",
    "\n",
    "    Returns:\n",
    "        dominant_freqs_list (list): List of arrays containing dominant frequencies for each dataset.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Input validation\n",
    "    if not (len(freqs_list) == len(amp_list) == len(labels)):\n",
    "        raise ValueError(\"freqs_list, amp_list, and labels must have the same length\")\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # List to store dominant frequencies\n",
    "    dominant_freqs_list = []\n",
    "    \n",
    "    # Process and plot each dataset\n",
    "    for freqs, amps, label in zip(freqs_list, amp_list, labels):\n",
    "        # Compute mean coefficients across time\n",
    "        mean_coeffs = np.mean(np.abs(amps), axis=1)\n",
    "        \n",
    "        # Call find_dominant_frequencies to get dominant frequencies\n",
    "        dominant_freqs = find_dominant_frequencies(amps, freqs, threshold)\n",
    "        dominant_freqs_list.append(dominant_freqs)\n",
    "        \n",
    "        # Plot mean coefficients\n",
    "        plt.plot(freqs, mean_coeffs, label=f\"Mean Coefficients - {label}\")\n",
    "        \n",
    "        # Plot dominant frequencies as scatter points\n",
    "        dominant_mask = np.isin(freqs, dominant_freqs)\n",
    "        plt.scatter(freqs[dominant_mask], mean_coeffs[dominant_mask], \n",
    "                   label=f\"Dominant Freqs - {label}\", s=50)\n",
    "\n",
    "    # Customize plot\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Wavelet Coefficient Magnitude\")\n",
    "    plt.title(title if title is not None else \"Dominant Frequencies Comparison\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return dominant_freqs_list\n",
    "\n",
    "def compare_midi_numbers(midi_lists):\n",
    "    \"\"\"\n",
    "    Compare multiple lists of MIDI numbers to find overlapping and unique numbers.\n",
    "\n",
    "    Parameters:\n",
    "        midi_lists (list): List of lists, each containing MIDI numbers (integers).\n",
    "\n",
    "    Returns:\n",
    "        result (list): [overlapping_numbers, leftover1, leftover2, ...], where:\n",
    "                            - overlapping_numbers: MIDI numbers present in all lists.\n",
    "                            - leftoveri: MIDI numbers unique to list i.\n",
    "    \"\"\"\n",
    "    if not midi_lists or len(midi_lists) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Convert all lists to sets for efficient comparison\n",
    "    sets = [set(midi_list) for midi_list in midi_lists]\n",
    "    \n",
    "    # Find numbers that appear in all lists (intersection of all sets)\n",
    "    overlapping = set.intersection(*sets) if sets else set()\n",
    "    \n",
    "    # For each set, find numbers unique to that set (not in any other set)\n",
    "    leftovers = []\n",
    "    for i, current_set in enumerate(sets):\n",
    "        # Create a set of all other sets combined\n",
    "        other_sets = set()\n",
    "        for j, s in enumerate(sets):\n",
    "            if i != j:\n",
    "                other_sets.update(s)\n",
    "        \n",
    "        # Find elements unique to the current set\n",
    "        unique_elements = current_set - other_sets\n",
    "        leftovers.append(sorted(list(unique_elements)))\n",
    "    \n",
    "    # Return the overlapping numbers and all leftovers\n",
    "    result = [sorted(list(overlapping))] + leftovers\n",
    "    return result\n",
    "\n",
    "def analyze_midi_distributions_with_lines(midi_files, line_groups, labels=None, mode='overlay', linestyle='dotted', linewidth=2):\n",
    "    \"\"\"\n",
    "    Analyze and visualize MIDI note distributions with reference lines for dominant frequencies.\n",
    "\n",
    "    Parameters:\n",
    "        midi_files (list): List of PrettyMIDI objects.\n",
    "        line_groups (list): List of MIDI number lists for comparison.\n",
    "        labels (list): Labels for each file (default: None, uses [\"MIDI 1\", \"MIDI 2\", ...]).\n",
    "        mode (str): Visualization mode ('individual' or 'overlay') (default: 'overlay').\n",
    "        linestyle (str): Style of vertical lines (default: 'dotted').\n",
    "        linewidth (float): Width of vertical lines (default: 2).\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary with indices as keys and (note_counts, mean_note) as values.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set default labels if not provided\n",
    "    if labels is None:\n",
    "        labels = [f\"MIDI {i+1}\" for i in range(len(midi_files))]\n",
    "    \n",
    "    # # Validate inputs\n",
    "    # if len(midi_files) != 2 or len(labels) < 2:\n",
    "    #     raise ValueError(\"Exactly two MIDI files and at least two labels are required\")\n",
    "    \n",
    "    # Assign colors based on labels\n",
    "    bar_colors = ['blue', 'orange', 'purple', 'pink', 'darkgreen', 'brown']  # Colors for bars and leftover lines\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Get all notes for overlap calculation\n",
    "    all_notes = []\n",
    "    for midi_file in midi_files:\n",
    "        notes = [note.pitch for instrument in midi_file.instruments for note in instrument.notes]\n",
    "        all_notes.append(notes)\n",
    "    \n",
    "    # Compute overlapping and leftover numbers\n",
    "    sorted_line_grps = compare_midi_numbers(line_groups)\n",
    "    overlapping_notes = sorted_line_grps[0] \n",
    "    leftover_notes = sorted_line_grps[1:]  # [leftover1, leftover2], ignoring overlapping\n",
    "    \n",
    "    # If overlay mode, prepare a single figure\n",
    "    if mode == 'overlay':\n",
    "        plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Process each file\n",
    "    for i, (midi_file, label) in enumerate(zip(midi_files, labels)):\n",
    "        try:\n",
    "            # Get all notes from all instruments in the MIDI file\n",
    "            notes = all_notes[i]\n",
    "            \n",
    "            # Count note occurrences\n",
    "            note_counts = Counter(notes)\n",
    "            \n",
    "            # Sort the notes for consistent plotting\n",
    "            sorted_notes = sorted(note_counts.items())\n",
    "            keys, values = zip(*sorted_notes) if sorted_notes else ([], [])\n",
    "            \n",
    "            # Compute the mean note\n",
    "            mean_note = np.mean(list(note_counts.keys())) if note_counts else 0\n",
    "            \n",
    "            # Store results\n",
    "            results[i] = (note_counts, mean_note)\n",
    "            \n",
    "            # Visualization\n",
    "            if mode == 'individual':\n",
    "                # Create a separate plot for each file\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.bar(keys, values, color=bar_colors[i], alpha=0.7)\n",
    "                # Mean line (red dotted)\n",
    "                plt.axvline(mean_note, color='red', linestyle='dotted', linewidth=2, \n",
    "                           label=f'Mean={mean_note:.2f}')\n",
    "                # Leftover notes with corresponding colors\n",
    "                for group_idx, leftover_group in enumerate(leftover_notes):\n",
    "                    for x in leftover_group:\n",
    "                        plt.axvline(x, color=bar_colors[group_idx], linestyle=linestyle, linewidth=linewidth, \n",
    "                                   label=f'{labels[group_idx]} Dom Freq={x}' if i == 0 else None)\n",
    "                # Add overlapping notes (green)\n",
    "                for x in overlapping_notes:\n",
    "                    plt.axvline(x, color='green', linestyle=linestyle, linewidth=linewidth-1, \n",
    "                            label=f'Overlap={x}', alpha=0.4)\n",
    "                plt.xlabel('MIDI Note Number')\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.title(f\"Histogram of {label} MIDI Note Frequencies\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            elif mode == 'overlay':\n",
    "                # Add to the overlay plot\n",
    "                plt.bar(keys, values, alpha=0.5, color=bar_colors[i], label=f\"{label} (Mean: {mean_note:.2f})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing MIDI {i+1}: {e}\")\n",
    "    \n",
    "    # Add lines and show the overlay plot if needed\n",
    "    if mode == 'overlay' and results:\n",
    "        # Add mean lines for both distributions\n",
    "        for i in range(len(midi_files)):\n",
    "            mean_note = results[i][1]\n",
    "            plt.axvline(mean_note, color='red', linestyle='dotted', linewidth=2, \n",
    "                       label=f'{labels[i]} Mean={mean_note:.2f}')\n",
    "        # Add leftover notes with corresponding colors\n",
    "        for group_idx, leftover_group in enumerate(leftover_notes):\n",
    "            for x in leftover_group:\n",
    "                plt.axvline(x, color=bar_colors[group_idx], linestyle=linestyle, linewidth=linewidth, \n",
    "                           label=f'{labels[group_idx]} Dom Freq={x}')\n",
    "        # Add overlapping notes (green)\n",
    "        for x in overlapping_notes:\n",
    "            plt.axvline(x, color='green', linestyle=linestyle, linewidth=linewidth-1, \n",
    "                    label=f'Overlap={x}', alpha=0.4)\n",
    "        plt.xlabel('MIDI Note Number')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(\"Distribution of MIDI Notes with Dominant Frequencies\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "#### periodicity vs wavelet entropy ####\n",
    "def periodicity_wavelet_entropy(data, wav=False):\n",
    "    \"\"\"\n",
    "    Calculate periodicity and wavelet entropy from MIDI or WAV data.\n",
    "\n",
    "    For MIDI data (wav=False), data should contain:\n",
    "    - time_series: Time values of the MIDI\n",
    "    - velocity_series: MIDI note velocities over time\n",
    "    - sample_rate: Sampling rate of the MIDI\n",
    "    - phase: Phase values\n",
    "    - amplitude: Amplitude values\n",
    "    - frequencies: Extracted frequency spectrum\n",
    "    \n",
    "    For WAV data (wav=True), data should contain:\n",
    "    - audio_data: Raw audio waveform\n",
    "    - sample_rate: Sampling rate of the audio\n",
    "    - phase: Phase values\n",
    "    - amplitude: Amplitude values\n",
    "    - frequencies: Extracted frequency spectrum\n",
    "\n",
    "    Parameters:\n",
    "        data (tuple): Data from get_amplitude_phase (WAV or MIDI format).\n",
    "        wav (bool): Whether data is from WAV files (True) or MIDI files (False) (default: False).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (periodicity_score, wavelet_entropy) where:\n",
    "            - periodicity_score: Measure of repeating patterns.\n",
    "            - wavelet_entropy: Measure of frequency spread.\n",
    "    \"\"\"\n",
    "    if wav:\n",
    "        # Unpack WAV data\n",
    "        audio_data, sample_rate, phase, amplitude, frequencies = data\n",
    "        \n",
    "        # Calculate autocorrelation on audio data\n",
    "        signal = audio_data\n",
    "    else:\n",
    "        # Unpack MIDI data\n",
    "        time_series, velocity_series, sample_rate, phase, amplitude, frequencies = data\n",
    "        \n",
    "        # Calculate autocorrelation on velocity series\n",
    "        signal = velocity_series\n",
    "    \n",
    "    # ---- Periodicity via Autocorrelation ----\n",
    "    autocorr = np.correlate(signal, signal, mode='full')\n",
    "    autocorr = autocorr[len(autocorr)//2:]  # Take positive lags only\n",
    "    periodicity_score = np.max(autocorr) / np.sum(autocorr)  # Normalize peak\n",
    "\n",
    "    # ---- Wavelet Entropy ----\n",
    "    energy_distribution = amplitude ** 2\n",
    "    \n",
    "    # Calculate entropy (common for both types)\n",
    "    energy_total = np.sum(energy_distribution, axis=0)\n",
    "    # Safe normalization with zero handling\n",
    "    normalized_energy = np.where(energy_total == 0, 0, energy_distribution / energy_total)\n",
    "    entropy = -np.sum(normalized_energy * np.log(normalized_energy), axis=0)  # Shannon Entropy\n",
    "    wavelet_entropy = np.mean(entropy)  # Average over time\n",
    "\n",
    "    return periodicity_score, wavelet_entropy\n",
    "\n",
    "def plot_entropy_vs_periodicity(entropy_list, periodicity_list, artists, title=\"Wavelet Entropy vs Periodicity\"):\n",
    "    \"\"\"\n",
    "    Plot wavelet entropy versus periodicity for multiple artists.\n",
    "\n",
    "    Parameters:\n",
    "        entropy_list (list): List of wavelet entropy values.\n",
    "        periodicity_list (list): List of periodicity scores.\n",
    "        artists (list): List of artist names corresponding to each data point.\n",
    "        title (str): Plot title (default: \"Wavelet Entropy vs Periodicity\").\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the plot.\n",
    "    \"\"\"\n",
    "    # Ensure the lists are of the same length\n",
    "    if len(entropy_list) != len(periodicity_list) or len(entropy_list) != len(artists):\n",
    "        raise ValueError(\"The lists and the artists must have the same length.\")\n",
    "    \n",
    "    # Create a color map with a unique color for each artist\n",
    "    unique_artists = list(set(artists))  # Get unique artists\n",
    "    colors = plt.cm.get_cmap('viridis', len(unique_artists))  # Using a colormap with distinct colors\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Loop over the unique artists and plot each one with a unique color\n",
    "    for idx, artist in enumerate(unique_artists):\n",
    "        # Get the indices for the current artist\n",
    "        indices = [i for i, a in enumerate(artists) if a == artist]\n",
    "        \n",
    "        # Plot the data points for the current artist\n",
    "        plt.scatter([entropy_list[i] for i in indices], \n",
    "                    [periodicity_list[i] for i in indices],\n",
    "                    color=colors(idx), label=artist)\n",
    "        \n",
    "        # Add labels for each point\n",
    "        for i in indices:\n",
    "            plt.text(entropy_list[i], periodicity_list[i], artist, fontsize=10, ha='center', va='top')\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.xlabel('Wavelet Entropy')\n",
    "    plt.ylabel('Periodicity')\n",
    "    plt.title(title)  # Use the custom title parameter\n",
    "    \n",
    "    # Add grid and show the plot\n",
    "    plt.legend(title='Artists')\n",
    "    plt.show()\n",
    "\n",
    "def shapiro_wilk_test(coeff, n_values=None, step=10, plot=True, titles=None):\n",
    "    \"\"\"\n",
    "    Perform Shapiro-Wilk test on wavelet coefficients to assess normality.\n",
    "\n",
    "    Parameters:\n",
    "        coeff (list): List of coefficient arrays from wavelet transformation.\n",
    "        n_values (list): Sample sizes to test (default: None, uses [10, 50, 100, 500, 800, 5000, 10000]).\n",
    "        step (int): Step size for sampling coefficients (default: 10).\n",
    "        plot (bool): Whether to generate plots (default: True).\n",
    "        titles (list): Titles for each coefficient list (default: None, uses [\"Coeff 1\", \"Coeff 2\", ...]).\n",
    "\n",
    "    Returns:\n",
    "        all_results (dict): Test results with 'individual' and 'flattened' statistics and p-values.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set default n_values if not provided\n",
    "    if n_values is None:\n",
    "        n_values = [10, 50, 100, 500, 800, 5000, 10000]\n",
    "    \n",
    "    # Set default titles if not provided\n",
    "    if titles is None:\n",
    "        titles = [f\"Coeff {i+1}\" for i in range(len(coeff))]\n",
    "    \n",
    "    # Ensure titles match the length of coeff\n",
    "    if len(titles) != len(coeff):\n",
    "        raise ValueError(\"Length of 'titles' must match the number of coefficient lists in 'coeff'\")\n",
    "    \n",
    "    # Initialize results dictionary for all coefficient lists\n",
    "    all_results = {}\n",
    "\n",
    "    # Number of coefficient lists\n",
    "    num_coeffs = len(coeff)\n",
    "\n",
    "    # Prepare for plotting\n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(2, num_coeffs, figsize=(5 * num_coeffs, 10), sharex=True)\n",
    "        if num_coeffs == 1:  # Handle a single coefficient list case\n",
    "            axes = np.array([[axes[0]], [axes[1]]])\n",
    "\n",
    "    # Loop through each coefficient list\n",
    "    for i, coeff_list in enumerate(coeff):\n",
    "        # Flatten all coefficients into one array\n",
    "        flattened_coeffs = np.concatenate(coeff_list)\n",
    "        \n",
    "        # Sample indices from coefficient lists\n",
    "        indices = range(0, len(coeff_list), step)\n",
    "        \n",
    "        # Initialize arrays to store results\n",
    "        stats_results = {n: [] for n in n_values}\n",
    "        p_results = {n: [] for n in n_values}\n",
    "        stats_flat = {n: None for n in n_values}\n",
    "        p_flat = {n: None for n in n_values}\n",
    "        \n",
    "        # Perform Shapiro-Wilk test for each coefficient list\n",
    "        for idx in indices:\n",
    "            sub_coeff_list = coeff_list[idx]\n",
    "            for n in n_values:\n",
    "                # Ensure n doesn't exceed the length of the coefficient list\n",
    "                n_test = min(n, len(sub_coeff_list))\n",
    "                stat, p = stats.shapiro(sub_coeff_list[:n_test])\n",
    "                stats_results[n].append(stat)\n",
    "                p_results[n].append(p)\n",
    "        \n",
    "        # Perform Shapiro-Wilk test for flattened data\n",
    "        for n in n_values:\n",
    "            n_test = min(n, len(flattened_coeffs))\n",
    "            stat, p = stats.shapiro(flattened_coeffs[:n_test])\n",
    "            stats_flat[n] = stat\n",
    "            p_flat[n] = p\n",
    "        \n",
    "        # Store results for current coefficient list\n",
    "        all_results[titles[i]] = {\n",
    "            'indices': indices,\n",
    "            'individual': {\n",
    "                'statistics': stats_results,\n",
    "                'p_values': p_results\n",
    "            },\n",
    "            'flattened': {\n",
    "                'statistics': stats_flat,\n",
    "                'p_values': p_flat\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Generate plots if requested\n",
    "        if plot:\n",
    "            ax1, ax2 = axes[0, i], axes[1, i]\n",
    "            \n",
    "            # Plot Shapiro-Wilk statistic\n",
    "            for n in n_values:\n",
    "                ax1.plot(indices, stats_results[n], marker='o', label=f'n={n} (Lists)')\n",
    "                ax1.axhline(y=stats_flat[n], linestyle='--', label=f'n={n} (Flattened)', alpha=0.7)\n",
    "            \n",
    "            ax1.set_title(titles[i])\n",
    "            ax1.set_ylabel(\"Test Statistic\")\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot p-values\n",
    "            for n in n_values:\n",
    "                ax2.plot(indices, p_results[n], marker='o', label=f'n={n} (Lists)')\n",
    "                ax2.axhline(y=p_flat[n], linestyle='--', label=f'n={n} (Flattened)', alpha=0.7)\n",
    "            \n",
    "            ax2.set_xlabel(\"Coefficient List Index\")\n",
    "            ax2.set_ylabel(\"p-value\")\n",
    "            ax2.axhline(y=0.05, color='r', linestyle='--', label='p=0.05 threshold')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    if plot:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    # Print summary for flattened data\n",
    "    for i, coeff_list in enumerate(coeff):\n",
    "        print(f\"\\nShapiro-Wilk Test Results for Flattened Coefficients - {titles[i]}:\")\n",
    "        for n in n_values:\n",
    "            stat = all_results[titles[i]]['flattened']['statistics'][n]\n",
    "            p = all_results[titles[i]]['flattened']['p_values'][n]\n",
    "            print(f\"n={n}: Statistic={stat:.4f}, p-value={p:.4f}, \"\n",
    "                  f\"{'Normal' if p > 0.05 else 'Not Normal'}\")\n",
    "        \n",
    "        # Print summary for a specific index as an example\n",
    "        example_idx = 0\n",
    "        print(f\"\\nExample results for index {list(indices)[example_idx]} (individual list):\")\n",
    "        for n in n_values:\n",
    "            stat = all_results[titles[i]]['individual']['statistics'][n][example_idx]\n",
    "            p = all_results[titles[i]]['individual']['p_values'][n][example_idx]\n",
    "            print(f\"n={n}: Statistic={stat:.4f}, p-value={p:.4f}, \"\n",
    "                  f\"{'Normal' if p > 0.05 else 'Not Normal'}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def print_periodicity_entropy(morlet_list, header=None,wav=True, artists=None):\n",
    "    \"\"\"\n",
    "    Calculate and print periodicity and wavelet entropy for multiple datasets.\n",
    "\n",
    "    Parameters:\n",
    "        morlet_list (list): List of Morlet wavelet data tuples from get_amplitude_phase.\n",
    "        header (str): Optional header for output (default: None).\n",
    "        wav (bool): Whether data is from WAV files (True) or MIDI files (False) (default: True).\n",
    "        artists (list): List of artist names (default: None, uses [\"Artist 1\", \"Artist 2\", ...]).\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary with artist names as keys and periodicity/entropy as values.\n",
    "    \"\"\"\n",
    "    # Import necessary libraries\n",
    "    import numpy as np\n",
    "    \n",
    "    # Use default artist names if none provided\n",
    "    if artists is None:\n",
    "        artists = [f\"Artist {i+1}\" for i in range(len(morlet_list))]\n",
    "    \n",
    "    # Check if the number of artist names matches the number of morlet lists\n",
    "    if len(artists) != len(morlet_list):\n",
    "        raise ValueError(\"Length of 'artists' must match the number of Morlet wavelet lists in 'morlet_list'\")\n",
    "    \n",
    "    # Initialize dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # Print header\n",
    "    print(header)\n",
    "    \n",
    "    # Loop through each artist and calculate periodicity and entropy\n",
    "    for i, morlet_data in enumerate(morlet_list):\n",
    "        # Compute periodicity and entropy\n",
    "        pe_result = periodicity_wavelet_entropy(morlet_data, wav=wav)\n",
    "        \n",
    "        # Save results in dictionary\n",
    "        results[artists[i]] = {\n",
    "            'Periodicity': pe_result[0],\n",
    "            'Wavelet Entropy': pe_result[1]\n",
    "        }\n",
    "        \n",
    "        # Print results for the current artist\n",
    "        print(f\"\\n{artists[i]}:\")\n",
    "        print(f\"Periodicity: {pe_result[0]:.7f}\")\n",
    "        print(f\"Wavelet Entropy: {pe_result[1]:.3f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7639bc8",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60293f8",
   "metadata": {},
   "source": [
    "## initialize midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c916d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# moanin (individual)\n",
    "moanin_lee_midi = pretty_midi.PrettyMIDI('data/moanin/midi/moanin_lee.mid')\n",
    "moanin_freddie_midi = pretty_midi.PrettyMIDI('data/moanin/midi/moanin_freddie.mid')\n",
    "moanin_art_midi = pretty_midi.PrettyMIDI('data/moanin/midi/moanin_art.mid')\n",
    "moanin_roy_midi = pretty_midi.PrettyMIDI('data/moanin/midi/moanin_roy.mid')\n",
    "moanin_ter_midi = pretty_midi.PrettyMIDI('data/moanin/midi/moanin_ter.mid')\n",
    "moanin_head_midi = pretty_midi.PrettyMIDI('data/moanin/midi/moanin_head.mid')\n",
    "\n",
    "# i rememebr clifford\n",
    "irmb_lee_midi = pretty_midi.PrettyMIDI('data/irmbclifford/midi/irmb_lee.mid')\n",
    "irmb_fred_midi = pretty_midi.PrettyMIDI('data/irmbclifford/midi/irmb_fred.mid')\n",
    "irmb_chet_midi = pretty_midi.PrettyMIDI('data/irmbclifford/midi/irmb_chet.mid')\n",
    "irmb_art_midi = pretty_midi.PrettyMIDI('data/irmbclifford/midi/irmb_art.mid')\n",
    "irmb_roy_midi = pretty_midi.PrettyMIDI('data/irmbclifford/midi/irmb_roy.mid')\n",
    "irmb_ter_midi = pretty_midi.PrettyMIDI('data/irmbclifford/midi/irmb_ter.mid')\n",
    "\n",
    "### songs not used in final writeup, but for previous iterations of capstone ###\n",
    "# blue train\n",
    "bluetrain_lee_midi = pretty_midi.PrettyMIDI('data/bluetrain/midi/bluetrain_lee.mid')\n",
    "bluetrain_chet_midi = pretty_midi.PrettyMIDI('data/bluetrain/midi/bluetrain_chet.mid')\n",
    "\n",
    "# moaning combined\n",
    "lee_midi = pretty_midi.PrettyMIDI('data/moanin/midi/lee.mid')\n",
    "others_midi = pretty_midi.PrettyMIDI('data/moanin/midi/others.mid')\n",
    "\n",
    "# canon in d\n",
    "hiromi_midi = pretty_midi.PrettyMIDI('data/canoninD/midi/hiromi.mid')\n",
    "pachabel_midi = pretty_midi.PrettyMIDI('data/canoninD/midi/pachelbel.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12349f8",
   "metadata": {},
   "source": [
    "## distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea66d23",
   "metadata": {},
   "source": [
    "### moanin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30260e41",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moaning_distributions = analyze_midi_distributions([moanin_lee_midi, moanin_freddie_midi, \n",
    "                                                    moanin_art_midi, moanin_roy_midi, \n",
    "                                                    moanin_ter_midi, moanin_head_midi], \n",
    "                                                    [\"Lee\", \"Freddie\", \"Art\", \"Roy\", \"Terence\", \"Head\"], \n",
    "                                                    mode='overlay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5471bfa",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "#### individual plots of artist vs head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f61aa",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moaning_distributions_lee = analyze_midi_distributions([moanin_lee_midi, moanin_head_midi], \n",
    "                                                       [\"Lee\",\"Head\"], mode='overlay')\n",
    "moaning_distributions_fred = analyze_midi_distributions([moanin_freddie_midi, moanin_head_midi], \n",
    "                                                        [\"Freddie\", \"Head\"], mode='overlay')\n",
    "moaning_distributions_art = analyze_midi_distributions([moanin_art_midi, moanin_head_midi], \n",
    "                                                       [\"Art\",\"Head\"], mode='overlay')\n",
    "moaning_distributions_roy = analyze_midi_distributions([moanin_roy_midi, moanin_head_midi], \n",
    "                                                       [\"Roy\", \"Head\"], mode='overlay')\n",
    "moaning_distributions_ter = analyze_midi_distributions([moanin_ter_midi, moanin_head_midi], \n",
    "                                                       [\"Terence\", \"Head\"], mode='overlay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10833822",
   "metadata": {},
   "source": [
    "#### f-test and KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927a978",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moaning_distributions_artists = [moaning_distributions_lee, \n",
    "                                moaning_distributions_fred, \n",
    "                                moaning_distributions_art, \n",
    "                                moaning_distributions_roy, \n",
    "                                moaning_distributions_ter]\n",
    "\n",
    "compare_variances_to_head(moaning_distributions_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a335153",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "artist_names = ['Lee', 'Freddie', 'Art', 'Roy', 'Terence']\n",
    "analyze_and_visualize_divergence(moaning_distributions, artist_names, title=\"Moanin'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29030e7",
   "metadata": {},
   "source": [
    "## networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62655fce",
   "metadata": {},
   "source": [
    "### moanin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf106347",
   "metadata": {},
   "source": [
    "#### all artists in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d8fd7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "midi_files = [\n",
    "    ('lee', moanin_lee_midi),\n",
    "    ('freddie', moanin_freddie_midi),\n",
    "    ('art', moanin_art_midi),\n",
    "    ('roy', moanin_roy_midi),\n",
    "    ('terence', moanin_ter_midi)\n",
    "]\n",
    "\n",
    "all_transition_probs = []\n",
    "all_labels = []\n",
    "\n",
    "for artist, midi_file in midi_files:\n",
    "    transition_probs, iois_probs, iois = get_prob_transitions(midi_file)\n",
    "    \n",
    "    all_transition_probs.append(transition_probs)\n",
    "    all_labels.append(f\"Moanin - {artist.capitalize()}\")\n",
    "\n",
    "# all pitch transitions\n",
    "G, positions = visualize_all_pitch_trans(\n",
    "                                    all_transition_probs,\n",
    "                                    plot_type='overlay',  \n",
    "                                    labels=all_labels,\n",
    "                                    title=\"'Moanin' Pitch Transitions\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397d327",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# strongest pitch transitions\n",
    "visualize_strongest_trans(\n",
    "    all_transition_probs,\n",
    "    plot_type='overlay',\n",
    "    labels=all_labels,\n",
    "    title=\"Moanin' Strongest Pitch Transitions\",\n",
    "    fixed_positions=positions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b5d26",
   "metadata": {},
   "source": [
    "#### each individual artist plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b0d7d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# all pitch transitions\n",
    "visualize_all_pitch_trans(\n",
    "    all_transition_probs,\n",
    "    plot_type='individual',  \n",
    "    labels=all_labels,\n",
    "    title=\"Moanin' Pitch Transitions\",\n",
    "    fixed_positions=positions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c76f92",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# strongest pitch transitions\n",
    "visualize_strongest_trans(\n",
    "    all_transition_probs,\n",
    "    plot_type='individual',\n",
    "    labels=all_labels,\n",
    "    title=\"Moanin' Strongest Pitch Transitions\",\n",
    "    fixed_positions=positions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1d566",
   "metadata": {},
   "source": [
    "#### heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a79c1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Run simulations for all artists\n",
    "all_theoretical_dists, all_simulated_dists, all_matrices, all_states_lists = run_all_simulations(\n",
    "    midi_files,\n",
    "    num_simulations=100,  # Number of simulations per artist\n",
    "    num_steps=10000,       # Steps per simulation\n",
    "    show_individual_plots=False,  # Show individual artist plots\n",
    "    show_comparison=True  # Show comparison heatmap plot of all artists\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b37d5",
   "metadata": {},
   "source": [
    "#### interval types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8e5fd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "###### for interval types ######\n",
    "# get all transition probabilities\n",
    "moanin_lee_trans = extract_transitions_from_midi('data/moanin/midi/moanin_lee.mid')\n",
    "moanin_fred_trans = extract_transitions_from_midi('data/moanin/midi/moanin_freddie.mid')\n",
    "moanin_art_trans = extract_transitions_from_midi('data/moanin/midi/moanin_art.mid')\n",
    "moanin_roy_trans = extract_transitions_from_midi('data/moanin/midi/moanin_roy.mid')\n",
    "moanin_ter_trans = extract_transitions_from_midi('data/moanin/midi/moanin_ter.mid')\n",
    "\n",
    "# and all edgecounts\n",
    "moanin_lee_edgecount = count_interval_edges(moanin_lee_trans)\n",
    "moanin_fred_edgecount = count_interval_edges(moanin_fred_trans)\n",
    "moanin_art_edgecount = count_interval_edges(moanin_art_trans)\n",
    "moanin_roy_edgecount = count_interval_edges(moanin_roy_trans)\n",
    "moanin_ter_edgecount = count_interval_edges(moanin_ter_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102a6cc",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# visualize for total, strongest only, and each interval type \n",
    "# plot for each artist\n",
    "moanin_lee_nx1 = visualize_pitch_trans_mod(moanin_lee_trans, title=\"Moanin — Lee\", plot_type='overlay', labels=labels)\n",
    "moanin_lee_nx2 = visualize_strongest_trans_mod(moanin_lee_trans, title=\"Moanin — Lee\", plot_type='overlay', labels=labels)\n",
    "moanin_lee_nx3 = visualize_pitch_trans_mod(moanin_lee_trans, title=\"Moanin — Lee\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ddf30",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moanin_fred_nx1 = visualize_pitch_trans_mod(moanin_fred_trans, title=\"Moanin — Freddie\", plot_type='overlay', labels=labels)\n",
    "moanin_fred_nx2 = visualize_strongest_trans_mod(moanin_fred_trans, title=\"Moanin — Freddie\", plot_type='overlay', labels=labels)\n",
    "moanin_fred_nx3 = visualize_pitch_trans_mod(moanin_fred_trans, title=\"Moanin — Freddie\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93520bb0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moanin_art_nx1 = visualize_pitch_trans_mod(moanin_art_trans, title=\"Moanin — Art\", plot_type='overlay', labels=labels)\n",
    "moanin_art_nx2 = visualize_strongest_trans_mod(moanin_art_trans, title=\"Moanin — Art\", plot_type='overlay', labels=labels)\n",
    "moanin_art_nx3 = visualize_pitch_trans_mod(moanin_art_trans, title=\"Moanin — Art\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c042a31",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moanin_roy_nx1 = visualize_pitch_trans_mod(moanin_roy_trans, title=\"Moanin — Roy\", plot_type='overlay', labels=labels)\n",
    "moanin_roy_nx2 = visualize_strongest_trans_mod(moanin_roy_trans, title=\"Moanin — Roy\", plot_type='overlay', labels=labels)\n",
    "moanin_roy_nx3 = visualize_pitch_trans_mod(moanin_roy_trans, title=\"Moanin — Roy\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc66717",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moanin_ter_nx1 = visualize_pitch_trans_mod(moanin_ter_trans, title=\"Moanin — Terence\", plot_type='overlay', labels=labels)\n",
    "moanin_ter_nx2 = visualize_strongest_trans_mod(moanin_ter_trans, title=\"Moanin — Terence\", plot_type='overlay', labels=labels)\n",
    "moanin_ter_nx3 = visualize_pitch_trans_mod(moanin_ter_trans, title=\"Moanin — Terence\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112973f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# edge counts\n",
    "print(\"Edge counts for each interval type\")\n",
    "print(\"Lee:\")\n",
    "print(moanin_lee_edgecount)\n",
    "print(\"Freddie:\")\n",
    "print(moanin_fred_edgecount)\n",
    "print(\"Art:\")\n",
    "print(moanin_art_edgecount)\n",
    "print(\"Roy:\")\n",
    "print(moanin_roy_edgecount)\n",
    "print(\"Terence:\")\n",
    "print(moanin_ter_edgecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1150892",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# plot bar chart of edge counts for each interval type\n",
    "# and standard deviation bar chart\n",
    "edge_counts = [\n",
    "    moanin_lee_edgecount,\n",
    "    moanin_fred_edgecount,\n",
    "    moanin_art_edgecount,\n",
    "    moanin_roy_edgecount,\n",
    "    moanin_ter_edgecount\n",
    "]\n",
    "artists = ['Lee', 'Freddie', 'Art', 'Roy', 'Terence']\n",
    "\n",
    "plot_interval_usage(edge_counts, artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980ec74",
   "metadata": {},
   "source": [
    "### i remember clifford"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb921e",
   "metadata": {},
   "source": [
    "#### all artists in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e86c7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "midi_files = [\n",
    "    ('lee', irmb_lee_midi),\n",
    "    ('freddie', irmb_fred_midi),\n",
    "    ('chet', irmb_chet_midi),\n",
    "    ('art', irmb_art_midi),\n",
    "    ('roy', irmb_roy_midi),\n",
    "    ('terence', irmb_ter_midi)\n",
    "]\n",
    "\n",
    "all_transition_probs = []\n",
    "all_labels = []\n",
    "\n",
    "for artist, midi_file in midi_files:\n",
    "    transition_probs, iois_probs, iois = get_prob_transitions(midi_file)\n",
    "    \n",
    "    all_transition_probs.append(transition_probs)\n",
    "    all_labels.append(f\"I Remember Clifford - {artist.capitalize()}\")\n",
    "\n",
    "\n",
    "# all pitch transitions\n",
    "G, positions = visualize_all_pitch_trans(\n",
    "                                    all_transition_probs,\n",
    "                                    plot_type='overlay',  \n",
    "                                    labels=all_labels,\n",
    "                                    title=\"I Remember Clifford Pitch Transitions\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f805737a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# strongest pitch transitions\n",
    "visualize_strongest_trans(\n",
    "    all_transition_probs,\n",
    "    plot_type='overlay',\n",
    "    labels=all_labels,\n",
    "    title=\"I Remember Clifford Pitch Transitions\",\n",
    "    fixed_positions=positions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f62d0f",
   "metadata": {},
   "source": [
    "#### each individual artist plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919e6d4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# all pitch transitions\n",
    "visualize_all_pitch_trans(\n",
    "    all_transition_probs,\n",
    "    plot_type='individual',  \n",
    "    labels=all_labels,\n",
    "    title=\"I Remember Clifford Pitch Transitions\",\n",
    "    fixed_positions=positions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfcae9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# strongest pitch transitions\n",
    "visualize_strongest_trans(\n",
    "    all_transition_probs,\n",
    "    plot_type='individual',\n",
    "    labels=all_labels,\n",
    "    title=\"I Remember Clifford Pitch Transitions\",\n",
    "    fixed_positions=positions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018310be",
   "metadata": {},
   "source": [
    "#### heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7996230",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Run simulations for all artists\n",
    "all_theoretical_dists, all_simulated_dists, all_matrices, all_states_lists = run_all_simulations(\n",
    "    midi_files,\n",
    "    num_simulations=100,  # Number of simulations per artist\n",
    "    num_steps=10000,       # Steps per simulation\n",
    "    show_individual_plots=False,  # Show individual artist plots\n",
    "    show_comparison=True  # Show comparison heatmap plot of all artists\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac373fc",
   "metadata": {},
   "source": [
    "#### interval types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fbf80",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "###### for interval types ######\n",
    "# get all transition probabilities\n",
    "irmb_lee_trans = extract_transitions_from_midi('data/irmbclifford/midi/irmb_lee.mid')\n",
    "irmb_fred_trans = extract_transitions_from_midi('data/irmbclifford/midi/irmb_fred.mid')\n",
    "irmb_chet_trans = extract_transitions_from_midi('data/irmbclifford/midi/irmb_chet.mid')\n",
    "irmb_art_trans = extract_transitions_from_midi('data/irmbclifford/midi/irmb_art.mid')\n",
    "irmb_roy_trans = extract_transitions_from_midi('data/irmbclifford/midi/irmb_roy.mid')\n",
    "irmb_ter_trans = extract_transitions_from_midi('data/irmbclifford/midi/irmb_ter.mid')\n",
    "\n",
    "# and all edgecounts\n",
    "irmb_lee_edgecount = count_interval_edges(irmb_lee_trans)\n",
    "irmb_fred_edgecount = count_interval_edges(irmb_fred_trans)\n",
    "irmb_chet_edgecount = count_interval_edges(irmb_chet_trans)\n",
    "irmb_art_edgecount = count_interval_edges(irmb_art_trans)\n",
    "irmb_roy_edgecount = count_interval_edges(irmb_roy_trans)\n",
    "irmb_ter_edgecount = count_interval_edges(irmb_ter_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef284e3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# visualize for total, strongest only, and each interval type \n",
    "# plot for each artist\n",
    "irmb_lee_nx1 = visualize_pitch_trans_mod(irmb_lee_trans, title=\"I Remember Clifford — Lee\", plot_type='overlay', labels=labels)\n",
    "irmb_lee_nx2 = visualize_strongest_trans_mod(irmb_lee_trans, title=\"I Remember Clifford — Lee\", plot_type='overlay', labels=labels)\n",
    "irmb_lee_nx3 = visualize_pitch_trans_mod(irmb_lee_trans, title=\"I Remember Clifford — Lee\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37148481",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "irmb_fred_nx1 = visualize_pitch_trans_mod(irmb_fred_trans, title=\"I Remember Clifford — Freddie\", plot_type='overlay', labels=labels)\n",
    "irmb_fred_nx2 = visualize_strongest_trans_mod(irmb_fred_trans, title=\"I Remember Clifford — Freddie\", plot_type='overlay', labels=labels)\n",
    "irmb_fred_nx3 = visualize_pitch_trans_mod(irmb_fred_trans, title=\"I Remember Clifford — Freddie\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422243b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "irmb_chet_nx1 = visualize_pitch_trans_mod(irmb_chet_trans, title=\"I Remember Clifford — Chet\", plot_type='overlay', labels=labels)\n",
    "irmb_chet_nx2 = visualize_strongest_trans_mod(irmb_chet_trans, title=\"I Remember Clifford — Chet\", plot_type='overlay', labels=labels)\n",
    "irmb_chet_nx3 = visualize_pitch_trans_mod(irmb_chet_trans, title=\"I Remember Clifford — Chet\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9332ce",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "irmb_art_nx1 = visualize_pitch_trans_mod(irmb_art_trans, title=\"I Remember Clifford — Art\", plot_type='overlay', labels=labels)\n",
    "irmb_art_nx2 = visualize_strongest_trans_mod(irmb_art_trans, title=\"I Remember Clifford — Art\", plot_type='overlay', labels=labels)\n",
    "irmb_art_nx3 = visualize_pitch_trans_mod(irmb_art_trans, title=\"I Remember Clifford — Art\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3082e91",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "irmb_roy_nx1 = visualize_pitch_trans_mod(irmb_roy_trans, title=\"I Remember Clifford — Roy\", plot_type='overlay', labels=labels)\n",
    "irmb_roy_nx2 = visualize_strongest_trans_mod(irmb_roy_trans, title=\"I Remember Clifford — Roy\", plot_type='overlay', labels=labels)\n",
    "irmb_roy_nx3 = visualize_pitch_trans_mod(irmb_roy_trans, title=\"I Remember Clifford — Roy\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d626c2d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "irmb_ter_nx1 = visualize_pitch_trans_mod(irmb_ter_trans, title=\"I Remember Clifford — Terence\", plot_type='overlay', labels=labels)\n",
    "irmb_ter_nx2 = visualize_strongest_trans_mod(irmb_ter_trans, title=\"I Remember Clifford — Terence\", plot_type='overlay', labels=labels)\n",
    "irmb_ter_nx3 = visualize_pitch_trans_mod(irmb_ter_trans, title=\"I Remember Clifford — Terence\", plot_type='individual', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4421b68",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# edge counts\n",
    "print(\"Edge counts for each interval type\")\n",
    "print(\"Lee:\")\n",
    "print(irmb_lee_edgecount)\n",
    "print(\"Freddie:\")\n",
    "print(irmb_fred_edgecount)\n",
    "print(\"Chet:\")\n",
    "print(irmb_chet_edgecount)\n",
    "print(\"Art:\")\n",
    "print(irmb_art_edgecount)\n",
    "print(\"Roy:\")\n",
    "print(irmb_roy_edgecount)\n",
    "print(\"Terence:\")\n",
    "print(irmb_ter_edgecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108bd5b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# plot bar chart of edge counts for each interval type\n",
    "# and standard deviation bar chart\n",
    "edge_counts = [\n",
    "    irmb_lee_edgecount,\n",
    "    irmb_fred_edgecount,\n",
    "    irmb_chet_edgecount,\n",
    "    irmb_art_edgecount,\n",
    "    irmb_roy_edgecount,\n",
    "    irmb_ter_edgecount\n",
    "]\n",
    "artists = ['Lee', 'Freddie', 'Chet', 'Art', 'Roy', 'Terence']\n",
    "\n",
    "plot_interval_usage(edge_counts, artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3157edb",
   "metadata": {},
   "source": [
    "## wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6048d39",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#### convert mp3 to wav files ####\n",
    "# moanin individual\n",
    "mp3_to_wav('data/moanin/stemmed/moanin_lee.mp3', 'data/moanin/wav/moanin_lee.wav')\n",
    "mp3_to_wav('data/moanin/stemmed/moanin_freddie.mp3', 'data/moanin/wav/moanin_fred.wav')\n",
    "mp3_to_wav('data/moanin/stemmed/moanin_art.mp3', 'data/moanin/wav/moanin_art.wav')\n",
    "mp3_to_wav('data/moanin/stemmed/moanin_roy.mp3', 'data/moanin/wav/moanin_roy.wav')\n",
    "mp3_to_wav('data/moanin/stemmed/moanin_ter.mp3', 'data/moanin/wav/moanin_ter.wav')\n",
    "\n",
    "# i remember clifford\n",
    "mp3_to_wav('data/irmbclifford/stemmed/irmb_lee.mp3', 'data/irmbclifford/wav/irmb_lee.wav')\n",
    "mp3_to_wav('data/irmbclifford/stemmed/irmb_fred.mp3', 'data/irmbclifford/wav/irmb_fred.wav')\n",
    "mp3_to_wav('data/irmbclifford/stemmed/irmb_chet.mp3', 'data/irmbclifford/wav/irmb_chet.wav')\n",
    "mp3_to_wav('data/irmbclifford/stemmed/irmb_art.mp3', 'data/irmbclifford/wav/irmb_art.wav')\n",
    "mp3_to_wav('data/irmbclifford/stemmed/irmb_roy.mp3', 'data/irmbclifford/wav/irmb_roy.wav')\n",
    "mp3_to_wav('data/irmbclifford/stemmed/irmb_ter.mp3', 'data/irmbclifford/wav/irmb_ter.wav')\n",
    "\n",
    "### songs not used in final writeup, but for previous iterations of capstone ###\n",
    "# blue train\n",
    "mp3_to_wav('data/bluetrain/stemmed/bluetrain_lee.mp3', 'data/bluetrain/wav/bluetrain_lee.wav')\n",
    "mp3_to_wav('data/bluetrain/stemmed/bluetrain_chet.mp3', 'data/bluetrain/wav/bluetrain_chet.wav')\n",
    "\n",
    "# canon in d\n",
    "mp3_to_wav('data/canoninD/stemmed/hiromi.mp3', 'data/canoninD/wav/hiromi.wav')\n",
    "mp3_to_wav('data/canoninD/stemmed/pachelbel.mp3', 'data/canoninD/wav/pachelbel.wav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9109d7",
   "metadata": {},
   "source": [
    "### moanin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6e7eb",
   "metadata": {},
   "source": [
    "#### prep data (midi)\n",
    "to show the differences in the plots. after this, only used wav data instead as it was more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaca161",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get the coefficients\n",
    "lee_coeff = prep_data_morlet('data/moanin/midi/moanin_lee.mid')\n",
    "fred_coeff = prep_data_morlet('data/moanin/midi/moanin_freddie.mid')\n",
    "art_coeff = prep_data_morlet('data/moanin/midi/moanin_art.mid')\n",
    "roy_coeff = prep_data_morlet('data/moanin/midi/moanin_roy.mid')\n",
    "ter_coeff = prep_data_morlet('data/moanin/midi/moanin_ter.mid')\n",
    "\n",
    "#### playing around with resolution by changing the wavelet width ####\n",
    "###### i did not put this in the final writeup, the resolution of the final image\n",
    "###### doesn't really seemed to have changed?\n",
    "# lee_coeff_hr = prep_data_morlet('data/moanin/midi/moanin_lee.mid', wavelet='cmor1.0-1.0')\n",
    "# fred_coeff_hr = prep_data_morlet('data/moanin/midi/moanin_freddie.mid', wavelet='cmor1.0-1.0')\n",
    "# art_coeff_hr = prep_data_morlet('data/moanin/midi/moanin_art.mid', wavelet='cmor1.0-1.0')\n",
    "\n",
    "# lee_morlet_hr = get_amplitude_phase(lee_coeff_hr)\n",
    "# fred_morlet_hr = get_amplitude_phase(fred_coeff_hr)\n",
    "# art_morlet_hr = get_amplitude_phase(art_coeff_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eafc46",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get amplitude and phase\n",
    "lee_morlet = get_amplitude_phase(lee_coeff)\n",
    "fred_morlet = get_amplitude_phase(fred_coeff)\n",
    "art_morlet = get_amplitude_phase(art_coeff)\n",
    "roy_morlet = get_amplitude_phase(roy_coeff)\n",
    "ter_morlet = get_amplitude_phase(ter_coeff)\n",
    "\n",
    "moanin_midi_list_morlet = [lee_morlet, fred_morlet, art_morlet, roy_morlet, ter_morlet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6873509a",
   "metadata": {},
   "source": [
    "#### plots (midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcc7b3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "morlet_analysis(moanin_midi_list_morlet, time_window=(0, 150), titles=['Lee', 'Freddie', 'Art', 'Roy', 'Terence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4afb3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_amp_phase(moanin_midi_list_morlet, titles=['Lee', 'Freddie', 'Art', 'Roy', 'Terence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d969d9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_amp_phase(moanin_midi_list_morlet, titles=['Lee', 'Freddie', 'Art', 'Roy', 'Terence'], time_window=(18, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea62abf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "##### not used in writeup\n",
    "# get frequencies amplitudes and coefficients\n",
    "freqs_list = [lee_morlet[4], fred_morlet[4], art_morlet[4], roy_morlet[4], ter_morlet[4]]\n",
    "amp_list = [lee_morlet[3], fred_morlet[3], art_morlet[3], roy_morlet[3], ter_morlet[3]]\n",
    "wavelet_coeff_list = [lee_coeff[0], fred_coeff[0], art_coeff[0], roy_coeff[0], ter_coeff[0]]\n",
    "\n",
    "# plot dominant frequencies\n",
    "dominant_freqs_list = plot_dominant_frequencies(freqs_list, amp_list, \n",
    "                                                labels=['Lee', 'Freddie', 'Art', 'Roy', 'Terence'], \n",
    "                                                title=\"Moanin' (midi)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536de11",
   "metadata": {},
   "source": [
    "#### periodicity vs entropy (midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac69988",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moanin_period_entropy = print_periodicity_entropy(moanin_midi_list_morlet, header=\"Moanin' (midi)\", artists=['Lee', 'Freddie', 'Art', 'Roy', 'Terence'], wav=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c581647",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "entropy_list = [pe['Wavelet Entropy'] for pe in moanin_period_entropy.values()]\n",
    "periodicity_list = [pe['Periodicity'] for pe in moanin_period_entropy.values()]\n",
    "artists = list(moanin_period_entropy.keys())\n",
    "\n",
    "plot_entropy_vs_periodicity(entropy_list, periodicity_list, artists, title=\"Moanin' (midi)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28c886",
   "metadata": {},
   "source": [
    "#### prep data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894988a7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get the coefficients\n",
    "lee_coeff = prep_data_morlet('data/moanin/wav/moanin_lee.wav', wav=True)\n",
    "fred_coeff = prep_data_morlet('data/moanin/wav/moanin_fred.wav', wav=True)\n",
    "art_coeff = prep_data_morlet('data/moanin/wav/moanin_art.wav', wav=True)\n",
    "roy_coeff = prep_data_morlet('data/moanin/wav/moanin_roy.wav', wav=True)\n",
    "ter_coeff = prep_data_morlet('data/moanin/wav/moanin_ter.wav', wav=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc3c5a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get amplitude and phase\n",
    "lee_morlet = get_amplitude_phase(lee_coeff, wav=True)\n",
    "fred_morlet = get_amplitude_phase(fred_coeff, wav=True)\n",
    "art_morlet = get_amplitude_phase(art_coeff, wav=True)\n",
    "roy_morlet = get_amplitude_phase(roy_coeff, wav=True)\n",
    "ter_morlet = get_amplitude_phase(ter_coeff, wav=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df61d3",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# adjust who you want to see here\n",
    "moanin_list_morlet = [lee_morlet, fred_morlet, art_morlet, roy_morlet, ter_morlet]\n",
    "artists_names = ['Lee', 'Freddie', 'Art', 'Roy', 'Terence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05f366",
   "metadata": {},
   "source": [
    "#### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec7f99",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "morlet_analysis(moanin_list_morlet, wav=True, time_window=(0, 150), \n",
    "                titles=artists_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f8449b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_amp_phase(moanin_list_morlet, wav=True, \n",
    "               titles=artists_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1509a5",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#### time window of 36-40 seconds\n",
    "plot_amp_phase(moanin_list_morlet, wav=True, \n",
    "               titles=artists_names, \n",
    "               time_window=(36, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0744a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#### time window of 18-22 seconds\n",
    "plot_amp_phase(moanin_list_morlet, wav=True, \n",
    "               titles=artists_names, \n",
    "               time_window=(18,22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788af5cf",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "##### not used in writeup\n",
    "# get frequencies amplitudes and coefficients\n",
    "freqs_list = [lee_morlet[4], fred_morlet[4], art_morlet[4], roy_morlet[4], ter_morlet[4]]\n",
    "amp_list = [lee_morlet[3], fred_morlet[3], art_morlet[3], roy_morlet[3], ter_morlet[3]]\n",
    "wavelet_coeff_list = [lee_coeff[0], fred_coeff[0], art_coeff[0], roy_coeff[0], ter_coeff[0]]\n",
    "\n",
    "# plot dominant frequencies\n",
    "dominant_freqs_list = plot_dominant_frequencies(freqs_list, amp_list, \n",
    "                                                labels=['Lee', 'Freddie', 'Art', 'Roy', 'Terence'], \n",
    "                                                title=\"Moanin'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70dd103",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "shapiro_wilk_test(wavelet_coeff_list, plot=True, titles=['Lee', 'Freddie', 'Art', 'Roy', 'Terence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6b888",
   "metadata": {},
   "source": [
    "#### periodicity vs entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ddb01",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "moanin_period_entropy = print_periodicity_entropy(moanin_list_morlet, \n",
    "                                                  header=\"Moanin'\", \n",
    "                                                  artists=artists_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd553d47",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "entropy_list = [pe['Wavelet Entropy'] for pe in moanin_period_entropy.values()]\n",
    "periodicity_list = [pe['Periodicity'] for pe in moanin_period_entropy.values()]\n",
    "artists = list(moanin_period_entropy.keys())\n",
    "\n",
    "plot_entropy_vs_periodicity(entropy_list, periodicity_list, artists, title=\"Moanin'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24f3b2",
   "metadata": {},
   "source": [
    "### i remember clifford"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fe38c",
   "metadata": {},
   "source": [
    "#### prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19d0d4",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get the coefficients\n",
    "lee_coeff = prep_data_morlet('data/irmbclifford/wav/irmb_lee.wav', wav=True)\n",
    "chet_coeff = prep_data_morlet('data/irmbclifford/wav/irmb_chet.wav', wav=True)\n",
    "fred_coeff = prep_data_morlet('data/irmbclifford/wav/irmb_fred.wav', wav=True)\n",
    "art_coeff = prep_data_morlet('data/irmbclifford/wav/irmb_art.wav', wav=True)\n",
    "roy_coeff = prep_data_morlet('data/irmbclifford/wav/irmb_roy.wav', wav=True)\n",
    "ter_coeff = prep_data_morlet('data/irmbclifford/wav/irmb_ter.wav', wav=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1adae2",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get amplitude and phase\n",
    "lee_morlet = get_amplitude_phase(lee_coeff, wav=True)\n",
    "chet_morlet = get_amplitude_phase(chet_coeff, wav=True)\n",
    "fred_morlet = get_amplitude_phase(fred_coeff, wav=True)\n",
    "art_morlet = get_amplitude_phase(art_coeff, wav=True)\n",
    "roy_morlet = get_amplitude_phase(roy_coeff, wav=True)\n",
    "ter_morlet = get_amplitude_phase(ter_coeff, wav=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbafbe",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# adjust who you want to see here\n",
    "irmb_list_morlet = [lee_morlet, chet_morlet, fred_morlet, art_morlet, roy_morlet, ter_morlet]\n",
    "artists_names = ['Lee', 'Chet', 'Freddie', 'Art', 'Roy', 'Terence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1ac6a",
   "metadata": {},
   "source": [
    "#### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865340a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "morlet_analysis(irmb_list_morlet, wav=True, time_window=(0, 150), \n",
    "                titles=artists_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae8bc0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_amp_phase(irmb_list_morlet, wav=True, \n",
    "               titles=artists_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87318880",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#### time window of 22-24 seconds\n",
    "plot_amp_phase(irmb_list_morlet, wav=True, \n",
    "               titles=artists_names, \n",
    "               time_window=(22,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e660b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "##### not used in writeup\n",
    "# get frequencies amplitudes and coefficients\n",
    "freqs_list = [lee_morlet[4], chet_morlet[4], fred_morlet[4], art_morlet[4], roy_morlet[4], ter_morlet[4]]\n",
    "amp_list = [lee_morlet[3], chet_morlet[3], fred_morlet[3], art_morlet[3], roy_morlet[3], ter_morlet[3]]\n",
    "wavelet_coeff_list = [lee_coeff[0], chet_coeff[0], fred_coeff[0], art_coeff[0], roy_coeff[0], ter_coeff[0]]\n",
    "\n",
    "# plot dominant frequencies\n",
    "dominant_freqs_list = plot_dominant_frequencies(freqs_list, amp_list, \n",
    "                                                labels=['Lee', 'Chet', 'Freddie', 'Art', 'Roy', 'Terence'], \n",
    "                                                title=\"I Remember Clifford\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e037ff",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "shapiro_wilk_test(wavelet_coeff_list, plot=True, titles=['Lee', 'Chet', 'Freddie', 'Art', 'Roy', 'Terence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a8da1",
   "metadata": {},
   "source": [
    "#### periodicity vs entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05a822",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "irmb_period_entropy = print_periodicity_entropy(irmb_list_morlet, \n",
    "                                                header=\"I Remember Clifford\", \n",
    "                                                artists=artists_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb2783",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "entropy_list = [pe['Wavelet Entropy'] for pe in irmb_period_entropy.values()]\n",
    "periodicity_list = [pe['Periodicity'] for pe in irmb_period_entropy.values()]\n",
    "artists = list(irmb_period_entropy.keys())\n",
    "\n",
    "plot_entropy_vs_periodicity(entropy_list, periodicity_list, artists, title=\"I Remember Clifford\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fef36",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.0",
   "language": "sage",
   "name": "SageMath-10.0"
  },
  "language_info": {
   "name": "sage"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
